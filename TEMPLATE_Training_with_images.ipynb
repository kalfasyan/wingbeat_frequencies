{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Invalid alias: The name clear can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name more can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name less can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name man can't be aliased because it is another magic command.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import glob, os, sys, io\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from wavhandler import *\n",
    "from utils import *\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.ERROR)\n",
    "np.random.seed(0)\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "seed = 2018\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = DenseNet121\n",
    "\n",
    "model_name = TEMP_DATADIR + 'wingbeats_imgs' + current_model.__name__\n",
    "\n",
    "best_weights_path = model_name + '.h5'\n",
    "log_path = model_name + '.log'\n",
    "monitor = 'val_acc'\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "es_patience = 7\n",
    "rlr_patience = 3\n",
    "\n",
    "SR = 8000\n",
    "N_FFT = 256\n",
    "HOP_LEN = int(N_FFT / 6)\n",
    "# input_shape = (129, 120, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.29it/s]\n"
     ]
    }
   ],
   "source": [
    "X_fnames, y = get_data(dataset='MOSQUITOES_IMGS_train', nr_signals=np.inf, only_names=True, text_labels=False)\n",
    "\n",
    "X_train, y_train = shuffle(X_fnames, y, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, stratify = y, test_size = 0.20, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_roll(data, u, shift_pct=0.006, axis=0):\n",
    "    if np.random.random() < u:\n",
    "        data = np.roll(data, int(round(np.random.uniform(-(len(data)*shift_pct), (len(data)*shift_pct)))), axis=axis)\n",
    "    return data\n",
    "\n",
    "def train_generator(X=X_train, y=y_train):\n",
    "    while True:\n",
    "        for start in range(0, len(X), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "\n",
    "            end = min(start + batch_size, len(X))\n",
    "            train_batch = X[start:end]\n",
    "            labels_batch = y[start:end]\n",
    "\n",
    "            for i in range(len(train_batch)):\n",
    "                temp = Image.open(train_batch[i])\n",
    "                data = np.array(temp.copy())[:,:,0]\n",
    "                temp.close()\n",
    "                data = np.expand_dims(data, axis=-1)\n",
    "                \n",
    "                data = shift_roll(data, u=0.5, shift_pct=0.006, axis=0)\n",
    "                data = shift_roll(data, u=0.5, shift_pct=0.25, axis=1)\n",
    "\n",
    "                x_batch.append(data)\n",
    "                y_batch.append(labels_batch[i])\n",
    "\n",
    "            x_batch = np.array(x_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "\n",
    "            y_batch = np_utils.to_categorical(y_batch, len(np.unique(y)))\n",
    "\n",
    "            yield x_batch, y_batch\n",
    "\n",
    "def valid_generator(X=X_val, y=y_val):\n",
    "    while True:\n",
    "        for start in range(0, len(X), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "\n",
    "            end = min(start + batch_size, len(X))\n",
    "            train_batch = X[start:end]\n",
    "            labels_batch = y[start:end]\n",
    "\n",
    "            for i in range(len(train_batch)):\n",
    "                temp = Image.open(train_batch[i])\n",
    "                data = np.array(temp.copy())[:,:,0]\n",
    "                temp.close()\n",
    "                data = np.expand_dims(data, axis=-1)\n",
    "\n",
    "                x_batch.append(data)\n",
    "                y_batch.append(labels_batch[i])\n",
    "\n",
    "            x_batch = np.array(x_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "\n",
    "            y_batch = np_utils.to_categorical(y_batch, len(np.unique(y)))\n",
    "\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for start in range(0, len(X_train), batch_size):\n",
    "#     x_batch = []\n",
    "#     y_batch = []\n",
    "\n",
    "#     end = min(start + batch_size, len(X_train))\n",
    "#     train_batch = X_train[start:end]\n",
    "#     labels_batch = y_train[start:end]\n",
    "\n",
    "#     for i in range(len(train_batch)):\n",
    "#         temp = Image.open(train_batch[i])\n",
    "#         data = np.array(temp.copy())[:,:,0]\n",
    "#         temp.close()\n",
    "#         data = np.expand_dims(data, axis=-1)\n",
    "\n",
    "#         data = shift_roll(data, u=0.5, shift_pct=0.006, axis=0)\n",
    "#         data = shift_roll(data, u=0.5, shift_pct=0.25, axis=1)\n",
    "#         break\n",
    "#     break\n",
    "# plt.imshow(data.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape = (129, 120, 1))\n",
    "\n",
    "model = current_model(input_tensor = img_input, classes = len(DataSet('MOSQUITOES').names), weights = None)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(monitor = monitor,\n",
    "                                filepath = best_weights_path,\n",
    "                                save_best_only = True,\n",
    "                                save_weights_only = True,\n",
    "                                verbose = 1),\n",
    "                    EarlyStopping(monitor = monitor,\n",
    "                                patience = es_patience,\n",
    "                                verbose = 1),\n",
    "                    ReduceLROnPlateau(monitor = monitor,\n",
    "                                factor = 0.1,\n",
    "                                patience = rlr_patience,\n",
    "                                verbose = 1),\n",
    "                    CSVLogger(filename = log_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    train_generator(),\n",
    "    steps_per_epoch = int(math.ceil(float(len(X_train)) / float(batch_size))),\n",
    "    validation_data = valid_generator(), \n",
    "    validation_steps = int(math.ceil(float(len(X_val)) / float(batch_size))),\n",
    "    epochs = 100,\n",
    "    callbacks=callbacks_list,\n",
    "    use_multiprocessing=True,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# model.load_weights(best_weights_path)\n",
    "\n",
    "# loss, acc = model.evaluate_generator(valid_generator,\n",
    "#         steps = int(math.ceil(float(len(X_test)) / float(batch_size))))\n",
    "\n",
    "# #print('loss:', loss)\n",
    "# print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# filenames, y = get_data(dataset='MOSQUITOES_IMGS_train', nr_signals=np.inf, only_names=True)\n",
    "\n",
    "# X_names, y = shuffle(filenames, y, random_state = seed)\n",
    "\n",
    "# X_tmp, _, y_tmp = get_data(dataset='MOSQUITOES_IMGS_train', nr_signals=10, only_names=False, text_labels=True)\n",
    "\n",
    "# train_data_dir = os.path.join(BASE_DIR, 'Wingbeats_spectrograms/train/')\n",
    "\n",
    "# datagen = ImageDataGenerator(rescale=1./255,\n",
    "#                             width_shift_range=0.2,\n",
    "#                             height_shift_range=0.05,\n",
    "#                             validation_split=0.2)\n",
    "\n",
    "# # train_generator = datagen.flow(X_train, y_train, batch_size=32, shuffle=True, subset='training')\n",
    "# # valid_generator = datagen.flow(X_train, y_train, batch_size=32, shuffle=True, subset='validation'))\n",
    "\n",
    "# train_generator = datagen.flow_from_directory(train_data_dir,\n",
    "#                                             target_size=(129,120),\n",
    "#                                             batch_size=32,\n",
    "#                                             shuffle=True,\n",
    "#                                             subset='training')\n",
    "\n",
    "# valid_generator = datagen.flow_from_directory(train_data_dir,\n",
    "#                                               target_size=(129,120),\n",
    "#                                               batch_size=32,\n",
    "#                                               subset='validation')\n",
    "\n",
    "# # fit parameters from data\n",
    "# datagen.fit(X_tmp)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # configure batch size and retrieve one batch of images\n",
    "# for X_batch, y_batch in datagen.flow(np.stack(X_tmp, axis=0), y_tmp, batch_size=11):\n",
    "#     # create a grid of 3x3 images\n",
    "#     plt.figure(figsize=(20,12))\n",
    "#     plt.grid(False)\n",
    "#     for i in range(0, 9):\n",
    "#         plt.subplot(340 + 1 + i)\n",
    "#         plt.grid(False)\n",
    "#         plt.imshow(X_batch[i].reshape(129, 120,3), cmap=plt.get_cmap('gray'))\n",
    "#     # show the plot\n",
    "#     plt.show()\n",
    "#     break\n",
    "\n",
    "# from keras.layers import Input\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
