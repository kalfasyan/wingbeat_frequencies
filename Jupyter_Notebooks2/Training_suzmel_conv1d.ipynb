{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from wavhandler import *\n",
    "from configs import DatasetConfiguration\n",
    "from utils_train import *\n",
    "from configs import *\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, classification_report, make_scorer, log_loss\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, GlobalAveragePooling2D\n",
    "import seaborn as sb\n",
    "import deepdish as dd\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "splitting = 'custom'\n",
    "data_setting = 'rawflt'\n",
    "model_setting = 'conv1d2'\n",
    "nb_classes = 2\n",
    "# clean = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{TEMP_DATADIR}/df_train_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_train = train.x.tolist()\n",
    "y_train = train.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(f\"{TEMP_DATADIR}/df_val_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_val = val.x.tolist()\n",
    "y_val = val.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{TEMP_DATADIR}/df_test_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_test = test.x.tolist()\n",
    "y_test = test.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "1    15620\n",
      "0    11226\n",
      "dtype: int64\n",
      "\n",
      "val: \n",
      "1    5206\n",
      "0    3743\n",
      "dtype: int64\n",
      "\n",
      "test: \n",
      "1    16340\n",
      "0    15530\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: \\n{pd.Series(y_train).value_counts()}\\n\")\n",
    "print(f\"val: \\n{pd.Series(y_val).value_counts()}\\n\")\n",
    "print(f\"test: \\n{pd.Series(y_test).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincf = TrainConfiguration(nb_classes=nb_classes, setting=data_setting,model_name=f\"Flies_{data_setting}_{model_setting}_{splitting}\", monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ INPUT SHAPE:(5000, 1)\n",
      "WARNING:tensorflow:From /home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Last 5 layers:\n",
      "dropout\n",
      "global_average_pooling1d\n",
      "dense\n",
      "dense_1\n",
      "activation\n"
     ]
    }
   ],
   "source": [
    "modelconf = ModelConfiguration(model_setting=model_setting, data_setting=data_setting, nb_classes=nb_classes, extra_dense_layer=False)\n",
    "model = modelconf.config\n",
    "\n",
    "# base_output = model.layers[-2].output\n",
    "# new_output = Dense(1, activation=None)(base_output)\n",
    "# new_output2 = Activation('sigmoid')(new_output)\n",
    "# model = Model(inputs=model.inputs, outputs=new_output2)\n",
    "\n",
    "print(\"Last 5 layers:\")\n",
    "for i in model.layers[-5:]:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4998, 16)          64        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 4998, 16)          64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2499, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2497, 32)          1568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2497, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1248, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1246, 64)          6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1246, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 623, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 621, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 621, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 310, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 308, 256)          98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 308, 256)          1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 154, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 154, 256)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 199,394\n",
      "Trainable params: 198,402\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import class_weight\n",
    "# weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "# class_weights = {i : weights[i] for i in range(nb_classes)}\n",
    "# print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "837/839 [============================>.] - ETA: 0s - loss: 0.2429 - acc: 0.8982\n",
      "Epoch 00001: val_loss improved from inf to 1.49531, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_conv1d2_custom.h5\n",
      "839/839 [==============================] - 69s 82ms/step - loss: 0.2429 - acc: 0.8982 - val_loss: 1.4953 - val_acc: 0.5401\n",
      "Epoch 2/100\n",
      "838/839 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9391\n",
      "Epoch 00002: val_loss improved from 1.49531 to 0.24462, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_conv1d2_custom.h5\n",
      "839/839 [==============================] - 70s 83ms/step - loss: 0.1558 - acc: 0.9389 - val_loss: 0.2446 - val_acc: 0.8900\n",
      "Epoch 3/100\n",
      "836/839 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9535\n",
      "Epoch 00003: val_loss did not improve from 0.24462\n",
      "839/839 [==============================] - 67s 80ms/step - loss: 0.1201 - acc: 0.9533 - val_loss: 0.6762 - val_acc: 0.8024\n",
      "Epoch 4/100\n",
      "837/839 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9632\n",
      "Epoch 00004: val_loss improved from 0.24462 to 0.18539, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_conv1d2_custom.h5\n",
      "839/839 [==============================] - 67s 80ms/step - loss: 0.0952 - acc: 0.9631 - val_loss: 0.1854 - val_acc: 0.9275\n",
      "Epoch 5/100\n",
      "837/839 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9707\n",
      "Epoch 00005: val_loss improved from 0.18539 to 0.09443, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_conv1d2_custom.h5\n",
      "839/839 [==============================] - 67s 79ms/step - loss: 0.0795 - acc: 0.9705 - val_loss: 0.0944 - val_acc: 0.9639\n",
      "Epoch 6/100\n",
      "837/839 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9735\n",
      "Epoch 00006: val_loss did not improve from 0.09443\n",
      "839/839 [==============================] - 68s 81ms/step - loss: 0.0702 - acc: 0.9734 - val_loss: 0.2244 - val_acc: 0.9285\n",
      "Epoch 7/100\n",
      "838/839 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9782\n",
      "Epoch 00007: val_loss did not improve from 0.09443\n",
      "839/839 [==============================] - 66s 79ms/step - loss: 0.0568 - acc: 0.9781 - val_loss: 0.2393 - val_acc: 0.9153\n",
      "Epoch 8/100\n",
      "836/839 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9800\n",
      "Epoch 00008: val_loss improved from 0.09443 to 0.09049, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_conv1d2_custom.h5\n",
      "839/839 [==============================] - 67s 80ms/step - loss: 0.0525 - acc: 0.9800 - val_loss: 0.0905 - val_acc: 0.9689\n",
      "Epoch 9/100\n",
      "836/839 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9825\n",
      "Epoch 00009: val_loss did not improve from 0.09049\n",
      "839/839 [==============================] - 67s 80ms/step - loss: 0.0461 - acc: 0.9824 - val_loss: 0.6902 - val_acc: 0.8584\n",
      "Epoch 10/100\n",
      "837/839 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9821\n",
      "Epoch 00010: val_loss did not improve from 0.09049\n",
      "839/839 [==============================] - 65s 78ms/step - loss: 0.0455 - acc: 0.9820 - val_loss: 7.0130 - val_acc: 0.6266\n",
      "Epoch 11/100\n",
      "836/839 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9848\n",
      "Epoch 00011: val_loss did not improve from 0.09049\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "839/839 [==============================] - 65s 77ms/step - loss: 0.0398 - acc: 0.9849 - val_loss: 0.1272 - val_acc: 0.9599\n",
      "Epoch 12/100\n",
      "838/839 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9933\n",
      "Epoch 00012: val_loss did not improve from 0.09049\n",
      "839/839 [==============================] - 65s 77ms/step - loss: 0.0194 - acc: 0.9933 - val_loss: 0.0978 - val_acc: 0.9718\n",
      "Epoch 13/100\n",
      "837/839 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9965\n",
      "Epoch 00013: val_loss improved from 0.09049 to 0.06497, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_conv1d2_custom.h5\n",
      "839/839 [==============================] - 66s 78ms/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.0650 - val_acc: 0.9797\n",
      "Epoch 14/100\n",
      "837/839 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9974\n",
      "Epoch 00014: val_loss did not improve from 0.06497\n",
      "839/839 [==============================] - 64s 77ms/step - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0953 - val_acc: 0.9750\n",
      "Epoch 15/100\n",
      "836/839 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9979\n",
      "Epoch 00015: val_loss did not improve from 0.06497\n",
      "839/839 [==============================] - 66s 78ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0988 - val_acc: 0.9750\n",
      "Epoch 16/100\n",
      "838/839 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9987\n",
      "Epoch 00016: val_loss did not improve from 0.06497\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "839/839 [==============================] - 66s 78ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0885 - val_acc: 0.9768\n",
      "Epoch 17/100\n",
      "836/839 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9990\n",
      "Epoch 00017: val_loss did not improve from 0.06497\n",
      "839/839 [==============================] - 66s 79ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0662 - val_acc: 0.9812\n",
      "Epoch 18/100\n",
      "836/839 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9990\n",
      "Epoch 00018: val_loss did not improve from 0.06497\n",
      "839/839 [==============================] - 65s 78ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.0695 - val_acc: 0.9808\n",
      "Epoch 19/100\n",
      "838/839 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 00019: val_loss did not improve from 0.06497\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "839/839 [==============================] - 66s 78ms/step - loss: 0.0036 - acc: 0.9993 - val_loss: 0.0685 - val_acc: 0.9819\n",
      "Epoch 20/100\n",
      "836/839 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 00020: val_loss did not improve from 0.06497\n",
      "839/839 [==============================] - 66s 79ms/step - loss: 0.0036 - acc: 0.9993 - val_loss: 0.0673 - val_acc: 0.9815\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_generator(X_train, y_train, \n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting,\n",
    "                                    binary_labels=False),\n",
    "                    steps_per_epoch = int(math.ceil(float(len(X_train)) / float(traincf.batch_size))),\n",
    "                    epochs = traincf.epochs,\n",
    "                    validation_data = valid_generator(X_val, y_val,\n",
    "                                                        batch_size=traincf.batch_size,\n",
    "                                                        target_names=np.unique(y_test).tolist(),\n",
    "                                                        setting=traincf.setting,\n",
    "                                                        binary_labels=False),\n",
    "                    validation_steps=int(math.ceil(float(len(X_val))/float(traincf.batch_size))),\n",
    "                    callbacks=traincf.callbacks_list)\n",
    "#              class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(valid_generator(X_test, y_test,\n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting, binary_labels=False),\n",
    "                              steps=int(math.ceil(float(len(X_test))/float(traincf.batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = np.where(pred <= 0.98, 0 , 1)p\n",
    "y_pred = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8926269958803627"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'actual')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "# cm = cm.astype(np.float) / cm.astype(np.float).sum(axis=0)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset - Suzukii_RL - exists: True\n"
     ]
    }
   ],
   "source": [
    "dset1 = DatasetConfiguration(names=['Suzukii_RL'])\n",
    "dset1.select(name='Suzukii_RL', species=['R','L'])\n",
    "dset1.read()\n",
    "dset1.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset1.labels = dset1.labels.apply(lambda x: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset1.fnames.shape\n",
    "dset1.labels.iloc[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predRL = model.predict_generator(valid_generator(dset1.fnames.tolist(), dset1.labels.tolist(),\n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(dset1.labels.tolist()).tolist(),\n",
    "                                    setting=traincf.setting, binary_labels=False),\n",
    "                              steps=int(math.ceil(float(len(dset1.fnames.tolist()))/float(traincf.batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predRL = np.argmax(predRL,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9692095421371774"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_true=dset1.labels.tolist(), y_pred=y_predRL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
