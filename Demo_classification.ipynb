{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import glob, os, sys, io\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from wavhandler import *\n",
    "from utils import *\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sn.set()\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.ERROR)\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mosquitos = pd.read_csv('./data/mosquitos.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  8.35it/s]\n"
     ]
    }
   ],
   "source": [
    "#bi_classes = ['LG_drosophila_10_09', 'LG_zapr_26_09']\n",
    "\n",
    "X_names, y = get_data(target_names=all_6, nr_signals=10000, only_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataframe of PSDs for all mosquito classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62205, 130)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat = make_df_parallel(df_mosquitos, setting='psd', names=X_names).T\n",
    "df_concat['label'] = y\n",
    "df_concat.label = df_concat.label.apply(lambda x: all_6[x])\n",
    "df_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the general dataframe (with custom features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mosquitos = pd.read_pickle('./data/mosquitos.pkl')\n",
    "df_mosquitos.drop(['names','pathlen','fnamelen','temp','humd'], axis=1, inplace=True)\n",
    "df_mosquitos.set_index('fname', inplace=True)\n",
    "labelarray_mosq = df_mosquitos.label.values\n",
    "print(df_mosquitos.shape)\n",
    "df_mosquitos.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(df_mosquitos, df_concat, left_index=True, right_index=True)\n",
    "# df.drop(['label_x','label_y'], axis=1, inplace=True)\n",
    "# # df.to_pickle('./data/big_df.pkl')\n",
    "# print(df.shape)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting which dataframe to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_concat#df_mosquitos.iloc[:,:-1]\n",
    "cols = df.columns.tolist()\n",
    "labels = df.label\n",
    "classes = np.unique(labels)\n",
    "#df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ae. aegypti            10762\n",
       "C. quinquefasciatus    10646\n",
       "An. gambiae            10395\n",
       "C. pipiens             10205\n",
       "Ae. albopictus         10103\n",
       "An. arabiensis         10094\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:14<00:00,  2.38s/it]\n",
      "100%|██████████| 120906/120906 [04:04<00:00, 494.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# X, y = get_data(target_names=all_6, nr_signals=20000, only_names=False)\n",
    "# X = transform_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling: \n",
      "Ae. aegypti            10094\n",
      "Ae. albopictus         10094\n",
      "C. quinquefasciatus    10094\n",
      "An. gambiae            10094\n",
      "An. arabiensis         10094\n",
      "C. pipiens             10094\n",
      "Name: 0, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = shuffle(df.iloc[:,:-1].values, labels, random_state=3)\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "ros = RandomUnderSampler(random_state=0)\n",
    "ros.fit(X,y)\n",
    "X, y = ros.fit_resample(X,y)\n",
    "print('After undersampling: \\n{}\\n'.format(pd.DataFrame(y).iloc[:,0].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = xgboost.XGBClassifier(n_estimators=650, learning_rate=0.2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=650,\n",
       "       n_jobs=-1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: XGBoost, ac: 0.781284\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "#cv_ac = cross_val_score(classifier, X, y, cv=3, scoring='accuracy')\n",
    "print(\"Name: %s, ac: %f\" % ('XGBoost', ac))\n",
    "#print(\"Name: %s, cv_ac: %f\" % ('XGBoost', np.mean(cv_ac)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(classifier.feature_importances_,\n",
    "                                    index = df.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(classifier, open(\"./data/pima.pickle.dat\", \"wb\"))\n",
    "pd.Series(df.index).to_csv('./data/pima_idx_used.csv')\n",
    "\n",
    "# loaded_model = pickle.load(open(\"pima.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X).to_csv('./data/unsupervised/mosquitos_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a dataframe of the confusion matrix to plot it\n",
    "df_cm = pd.DataFrame(cm, index=[i for i in classes], \n",
    "                    columns=[i for i in classes])\n",
    "plt.figure(figsize=(12,7))\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.concatenate((X, y.reshape(-1,1)), axis=1)\n",
    "sub = pd.DataFrame(sub)\n",
    "sub.sort_values(by=sub.iloc[:,-1].name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.dropna(how='any', axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "D = squareform(pdist(sub.values[:,:-1], metric='euclidean'))\n",
    "#‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘cityblock’, ‘correlation’, \n",
    "#‘cosine’, ‘dice’, ‘euclidean’, ‘hamming’, ‘jaccard’, ‘kulsinski’, \n",
    "#‘mahalanobis’, ‘matching’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’, \n",
    "#‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’, ‘yule’.\n",
    "\n",
    "plt.figure(figsize=(20,14))\n",
    "plt.imshow(D)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_median_signal(D=None):\n",
    "    a = np.nanmedian(D, axis=0)\n",
    "    minval = np.argmin(a[np.nonzero(a)])\n",
    "    return minval # index - argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sub.values[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "xx = X[50,:]\n",
    "yy = X[13,:]\n",
    "\n",
    "distance, path = fastdtw(xx, yy, dist=euclidean)\n",
    "print(distance)\n",
    "\n",
    "xx_idx = np.array([path[i][0] for i in range(len(path))])\n",
    "yy_idx = np.array([path[i][1] for i in range(len(path))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(xx, c='r')\n",
    "plt.plot(yy, c='y')\n",
    "plt.legend(('xx','yy'))\n",
    "#plt.ylim(0,0.15)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(xx[xx_idx], c='b')\n",
    "plt.plot(yy[yy_idx], c='c')\n",
    "plt.legend(('xx_new','yy_new'))\n",
    "#plt.ylim(0,0.15)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(xx, c='r')\n",
    "plt.plot(xx[xx_idx], c='b')\n",
    "plt.legend(('xx','xx_new'))\n",
    "#plt.ylim(0,0.15)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(yy, c='y')\n",
    "plt.plot(yy[yy_idx], c='c')\n",
    "plt.legend(('yy','yy_new'))\n",
    "#plt.ylim(0,0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_signal_idx = find_median_signal(D=X.astype(float))\n",
    "median_signal = X[median_signal_idx,:]\n",
    "plt.plot(median_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape\n",
    "\n",
    "D_dtw = np.zeros((600,600))\n",
    "\n",
    "def warp_with_median_signal(xx, median_signal, distance=euclidean):\n",
    "    _, path = fastdtw(xx, median_signal, dist=distance)\n",
    "    \n",
    "    idx = np.array([path[i][0] for i in range(len(path))])\n",
    "    sig = xx[idx]\n",
    "    \n",
    "    return sig[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = X[10,:]\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(warp_with_median_signal(sig, median_signal, distance=euclidean))\n",
    "#plt.xlim(0,2500)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sig)\n",
    "#plt.xlim(0,2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "XX = []\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    XX.append(warp_with_median_signal(X[i,:], median_signal, distance=euclidean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(XX[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = np.vstack(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X, y = shuffle(XX, y, random_state=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "classifier = xgboost.XGBClassifier(n_estimators=300, n_jobs=-1)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "print(\"Name: %s, ac: %f\" % ('XGBoost', ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
