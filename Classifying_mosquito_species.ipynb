{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wavhandler import *\n",
    "from utils_train import *\n",
    "import soundfile as sf\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "data1 = Dataset('Wingbeats')\n",
    "data1.read(data='all', setting='read', labels='text', loadmat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2018\n",
    "np.random.seed(seed)\n",
    "\n",
    "current_model = DenseNet121\n",
    "\n",
    "# Training setting - What kind of data to use\n",
    "if setting in ['gasf','gadf', 'mtf', 'rp']:\n",
    "    input_shape = (150,150,1)\n",
    "elif setting=='stft':\n",
    "    input_shape = (129, 120, 1)\n",
    "else:\n",
    "    raise ValueError('No valid data setting provided')\n",
    "\n",
    "# More settings\n",
    "model_name = model_name + '_' + setting + '_' + current_model.__name__\n",
    "top_weights_path = TEMP_DATADIR + str(model_name) + '.h5'\n",
    "logfile = TEMP_DATADIR + str(model_name) + '.log'\n",
    "batch_size = 32\n",
    "monitor = 'val_acc'\n",
    "es_patience = 7\n",
    "rlr_patience = 3\n",
    "target_names = np.unique(y)\n",
    "\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "X = X_names#np.array(X_names).reshape(-1,1)\n",
    "\n",
    "X, y = shuffle(X, y, random_state=0) \n",
    "\n",
    "if undersampling:\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    ros = RandomUnderSampler(random_state=0)\n",
    "    ros.fit(X,y)\n",
    "    X, y = ros.fit_resample(X,y)\n",
    "    X = pd.Series(X.ravel()).tolist()\n",
    "    print('After undersampling: \\n{}\\n'.format(pd.DataFrame(y).iloc[:,0].value_counts()))\n",
    "else:\n",
    "    print('Class balance: \\n{}\\n'.format(pd.DataFrame(y).iloc[:,0].value_counts()))\n",
    "\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = train_test_val_split(X,y, random_state=0)\n",
    "\n",
    "# Model parameters\n",
    "img_input = Input(shape = input_shape)\n",
    "model = current_model(input_tensor = img_input, classes = len(target_names), weights = None)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# Define Callbacks\n",
    "callbacks_list = [ModelCheckpoint(monitor = monitor,\n",
    "                                filepath = top_weights_path,\n",
    "                                save_best_only = True,\n",
    "                                save_weights_only = True,\n",
    "                                verbose = 1),\n",
    "                    EarlyStopping(monitor = monitor,\n",
    "                                patience = es_patience,\n",
    "                                verbose = 1),\n",
    "                    ReduceLROnPlateau(monitor = monitor,\n",
    "                                factor = 0.1,\n",
    "                                patience = rlr_patience,\n",
    "                                verbose = 1),\n",
    "                    CSVLogger(filename = logfile)]\n",
    "# TRAIN\n",
    "model.fit_generator(train_generator(X_train,\n",
    "                                    y_train, \n",
    "                                    batch_size=batch_size, \n",
    "                                    target_names=target_names,\n",
    "                                    setting=setting),\n",
    "                    steps_per_epoch = int(math.ceil(float(len(X_train)) / float(batch_size))),\n",
    "                    epochs=100, \n",
    "                    validation_data = valid_generator(X_val,\n",
    "                                                    y_val, \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    target_names=target_names,\n",
    "                                                    setting=setting), \n",
    "                    validation_steps = int(math.ceil(float(len(X_test)) / float(batch_size))),\n",
    "                    callbacks = callbacks_list)\n",
    "# EVALUATE\n",
    "model.load_weights(top_weights_path)\n",
    "loss, acc = model.evaluate_generator(valid_generator(X_test, \n",
    "                                                    y_test, \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    setting=setting, \n",
    "                                                    target_names=target_names),\n",
    "        steps = int(math.ceil(float(len(X_test)) / float(batch_size))))\n",
    "\n",
    "print('loss', loss)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# SAVING\n",
    "from keras.models import model_from_yaml\n",
    "model_yaml = model.to_yaml()\n",
    "with open(TEMP_DATADIR + model_name + \".yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "model.save_weights(TEMP_DATADIR + model_name + \"_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
