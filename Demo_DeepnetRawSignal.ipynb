{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import glob, os, sys, io\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "\n",
    "from wavhandler import *\n",
    "from utils import *\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.ERROR)\n",
    "np.random.seed(0)\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:15<00:00,  2.57s/it]\n"
     ]
    }
   ],
   "source": [
    "X,y = get_data(target_names=all_6, nr_signals=20000, only_names=False)\n",
    "#X = transform_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label to onehot\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=6)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=6)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kalfasyan/miniconda3/envs/wingbeats/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "# Build the Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(16, 3, activation='relu', input_shape=(5000, 1)))\n",
    "model.add(Conv1D(16, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deep_1'\n",
    "top_weights_path = './data/model_' + str(model_name) + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [ModelCheckpoint(top_weights_path, monitor = 'val_acc', verbose = 1, save_best_only = True, save_weights_only = True),\n",
    "    EarlyStopping(monitor = 'val_acc', patience = 6, verbose = 1),\n",
    "    ReduceLROnPlateau(monitor = 'val_acc', factor = 0.1, patience = 3, verbose = 1),\n",
    "    CSVLogger('model_' + str(model_name) + '.log')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96724 samples, validate on 24182 samples\n",
      "Epoch 1/100\n",
      "96724/96724 [==============================] - 600s 6ms/step - loss: 0.6198 - acc: 0.7673 - val_loss: 1.6741 - val_acc: 0.5633\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.56331, saving model to model_deep_1.h5\n",
      "Epoch 2/100\n",
      "96724/96724 [==============================] - 595s 6ms/step - loss: 0.4051 - acc: 0.8492 - val_loss: 1.8552 - val_acc: 0.5222\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.56331\n",
      "Epoch 3/100\n",
      "96724/96724 [==============================] - 593s 6ms/step - loss: 0.3529 - acc: 0.8680 - val_loss: 3.4001 - val_acc: 0.4790\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.56331\n",
      "Epoch 4/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.3185 - acc: 0.8804 - val_loss: 9.7684 - val_acc: 0.2241\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.56331\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.2495 - acc: 0.9075 - val_loss: 0.2732 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.56331 to 0.89662, saving model to model_deep_1.h5\n",
      "Epoch 6/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.2318 - acc: 0.9134 - val_loss: 0.3563 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89662\n",
      "Epoch 7/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.2247 - acc: 0.9172 - val_loss: 5.7267 - val_acc: 0.4940\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89662\n",
      "Epoch 8/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.2162 - acc: 0.9204 - val_loss: 0.6437 - val_acc: 0.8085\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89662\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.2017 - acc: 0.9260 - val_loss: 0.2620 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.89662 to 0.90179, saving model to model_deep_1.h5\n",
      "Epoch 10/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1992 - acc: 0.9273 - val_loss: 0.6833 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90179\n",
      "Epoch 11/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1979 - acc: 0.9275 - val_loss: 0.2371 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.90179 to 0.91167, saving model to model_deep_1.h5\n",
      "Epoch 12/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1963 - acc: 0.9281 - val_loss: 0.7059 - val_acc: 0.8074\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.91167\n",
      "Epoch 13/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1949 - acc: 0.9281 - val_loss: 0.2472 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.91167\n",
      "Epoch 14/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1952 - acc: 0.9279 - val_loss: 0.2376 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.91167 to 0.91246, saving model to model_deep_1.h5\n",
      "Epoch 15/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1935 - acc: 0.9292 - val_loss: 0.2570 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.91246\n",
      "Epoch 16/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1924 - acc: 0.9297 - val_loss: 0.2523 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.91246\n",
      "Epoch 17/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1918 - acc: 0.9296 - val_loss: 0.3009 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.91246\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 18/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1909 - acc: 0.9297 - val_loss: 0.2340 - val_acc: 0.9128\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.91246 to 0.91279, saving model to model_deep_1.h5\n",
      "Epoch 19/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1908 - acc: 0.9300 - val_loss: 0.2337 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.91279 to 0.91349, saving model to model_deep_1.h5\n",
      "Epoch 20/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1899 - acc: 0.9302 - val_loss: 0.2336 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.91349\n",
      "Epoch 21/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1890 - acc: 0.9300 - val_loss: 0.2337 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.91349\n",
      "Epoch 22/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1884 - acc: 0.9313 - val_loss: 0.2339 - val_acc: 0.9128\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.91349\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 23/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1881 - acc: 0.9310 - val_loss: 0.2336 - val_acc: 0.9128\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.91349\n",
      "Epoch 24/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1897 - acc: 0.9313 - val_loss: 0.2337 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.91349\n",
      "Epoch 25/100\n",
      "96724/96724 [==============================] - 594s 6ms/step - loss: 0.1880 - acc: 0.9312 - val_loss: 0.2335 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.91349\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 00025: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd874d5dd8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=100, validation_data = [X_test, y_test], callbacks = callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24182/24182 [==============================] - 49s 2ms/step\n",
      "Test accuracy: 0.9134893722652886\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(top_weights_path)\n",
    "loss, acc = model.evaluate(X_test, y_test, batch_size=16)\n",
    "\n",
    "#print('loss', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
