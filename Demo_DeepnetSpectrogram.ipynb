{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import glob, os, sys, io\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "\n",
    "from wavhandler import *\n",
    "from utils import *\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.ERROR)\n",
    "np.random.seed(0)\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from scipy import signal\n",
    "import math\n",
    "seed = 2018\n",
    "np.random.seed(seed)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from keras import Model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.nasnet import NASNetLarge, NASNetMobile\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = DenseNet121\n",
    "# current_model = DenseNet169\n",
    "# current_model = DenseNet201\n",
    "# current_model = InceptionResNetV2\n",
    "# current_model = InceptionV3\n",
    "# current_model = MobileNet\n",
    "# current_model = NASNetLarge\n",
    "# current_model = NASNetMobile\n",
    "# current_model = VGG16\n",
    "# current_model = VGG19\n",
    "# current_model = Xception\n",
    "\n",
    "model_name = TEMP_DATADIR + 'wingbeats_190123_' + current_model.__name__\n",
    "\n",
    "best_weights_path = model_name + '.h5'\n",
    "log_path = model_name + '.log'\n",
    "monitor = 'val_acc'\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "es_patience = 7\n",
    "rlr_patience = 3\n",
    "\n",
    "SR = 8000\n",
    "N_FFT = 256\n",
    "HOP_LEN = int(N_FFT / 6)\n",
    "input_shape = (129, 120, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(x, wshift, hshift, row_axis = 0, col_axis = 1, channel_axis = 2, fill_mode = 'constant', cval = 0.):\n",
    "    h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "    tx = hshift * h\n",
    "    ty = wshift * w\n",
    "    translation_matrix = np.array([[1, 0, tx],\n",
    "                                   [0, 1, ty],\n",
    "                                   [0, 0, 1]])\n",
    "    transform_matrix = translation_matrix\n",
    "    x = image.apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n",
    "    return x\n",
    "\n",
    "def random_data_shift(data, w_limit = (-0.25, 0.25), h_limit = (-0.0, 0.0), cval = 0., u = 0.5):\n",
    "    if np.random.random() < u:\n",
    "        wshift = np.random.uniform(w_limit[0], w_limit[1])\n",
    "        hshift = np.random.uniform(h_limit[0], h_limit[1])\n",
    "        data = shift(data, wshift, hshift, cval = cval)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names,y = get_data(target_names=all_6, nr_signals=999999, only_names=True)\n",
    "\n",
    "X_names, y = shuffle(X_names, y, random_state = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_names, y, stratify = y, test_size = 0.20, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(X_train), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "\n",
    "            end = min(start + batch_size, len(X_train))\n",
    "            train_batch = X_train[start:end]\n",
    "            labels_batch = y_train[start:end]\n",
    "\n",
    "            for i in range(len(train_batch)):\n",
    "                data, rate = librosa.load(train_batch[i], sr = SR)\n",
    "\n",
    "                #data = random_data_shift(data, u = 1.0)\n",
    "\n",
    "                data = librosa.stft(data, n_fft = N_FFT, hop_length = HOP_LEN)\n",
    "                data = librosa.amplitude_to_db(np.abs(data))\n",
    "#                 data = np.abs(data)\n",
    "                data = np.flipud(data)\n",
    "\n",
    "                data = np.expand_dims(data, axis = -1)\n",
    "                data = random_data_shift(data, w_limit = (-0.25, 0.25), h_limit = (-0.0, 0.0), cval = np.min(data), u = 1.0)\n",
    "\n",
    "                # data = np.squeeze(data, axis = -1)\n",
    "                # plt.imshow(data, cmap = 'gray')\n",
    "                # plt.show()\n",
    "                # data = np.expand_dims(data, axis = -1)\n",
    "\n",
    "                x_batch.append(data)\n",
    "                y_batch.append(labels_batch[i])\n",
    "\n",
    "            x_batch = np.array(x_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "\n",
    "            y_batch = np_utils.to_categorical(y_batch, len(target_names))\n",
    "\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(X_test), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "\n",
    "            end = min(start + batch_size, len(X_test))\n",
    "            test_batch = X_test[start:end]\n",
    "            labels_batch = y_test[start:end]\n",
    "\n",
    "            for i in range(len(test_batch)):\n",
    "                data, rate = librosa.load(test_batch[i], sr = SR)\n",
    "\n",
    "                data = librosa.stft(data, n_fft = N_FFT, hop_length = HOP_LEN)\n",
    "                data = librosa.amplitude_to_db(np.abs(data))\n",
    "#                 data = np.abs(data)\n",
    "                data = np.flipud(data)\n",
    "\n",
    "                data = np.expand_dims(data, axis = -1)\n",
    "\n",
    "                x_batch.append(data)\n",
    "                y_batch.append(labels_batch[i])\n",
    "\n",
    "            x_batch = np.array(x_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "\n",
    "            y_batch = np_utils.to_categorical(y_batch, len(target_names))\n",
    "\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_names = all_6\n",
    "# for start in range(0, len(X_test), batch_size):\n",
    "#     x_batch = []\n",
    "#     y_batch = []\n",
    "\n",
    "#     end = min(start + batch_size, len(X_test))\n",
    "#     test_batch = X_test[start:end]\n",
    "#     labels_batch = y_test[start:end]\n",
    "\n",
    "#     for i in range(len(test_batch)):\n",
    "#         data, rate = librosa.load(test_batch[i], sr = SR)\n",
    "\n",
    "#         data = librosa.stft(data, n_fft = N_FFT, hop_length = HOP_LEN)\n",
    "# #                 data = librosa.amplitude_to_db(data)\n",
    "#         data = np.abs(data)\n",
    "#         data = np.flipud(data)\n",
    "\n",
    "#         data = np.expand_dims(data, axis = -1)\n",
    "\n",
    "#         x_batch.append(data)\n",
    "#         y_batch.append(labels_batch[i])\n",
    "\n",
    "#     x_batch = np.array(x_batch, np.float32)\n",
    "#     y_batch = np.array(y_batch, np.float32)\n",
    "\n",
    "#     y_batch = np_utils.to_categorical(y_batch, len(target_names))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,14))\n",
    "# plt.imshow(x_batch[0].squeeze())\n",
    "# plt.colorbar()\n",
    "# plt.grid(False)\n",
    "# plt.title(str(x_batch[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = all_6\n",
    "\n",
    "img_input = Input(shape = input_shape)\n",
    "\n",
    "model = current_model(input_tensor = img_input, classes = len(target_names), weights = None)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(monitor = monitor,\n",
    "                                filepath = best_weights_path,\n",
    "                                save_best_only = True,\n",
    "                                save_weights_only = True,\n",
    "                                verbose = 1),\n",
    "                    EarlyStopping(monitor = monitor,\n",
    "                                patience = es_patience,\n",
    "                                verbose = 1),\n",
    "                    ReduceLROnPlateau(monitor = monitor,\n",
    "                                factor = 0.1,\n",
    "                                patience = rlr_patience,\n",
    "                                verbose = 1),\n",
    "                    CSVLogger(filename = log_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator(),\n",
    "    steps_per_epoch = int(math.ceil(float(len(X_train)) / float(batch_size))),\n",
    "    validation_data = valid_generator(),\n",
    "    validation_steps = int(math.ceil(float(len(X_test)) / float(batch_size))),\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks_list,\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(best_weights_path)\n",
    "\n",
    "loss, acc = model.evaluate_generator(valid_generator(),\n",
    "        steps = int(math.ceil(float(len(X_test)) / float(batch_size))))\n",
    "\n",
    "#print('loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
