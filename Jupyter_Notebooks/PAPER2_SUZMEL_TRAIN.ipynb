{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from wavhandler import *\n",
    "from configs import DatasetConfiguration\n",
    "from utils_train import *\n",
    "from configs import *\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, classification_report, make_scorer, log_loss\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "import seaborn as sb\n",
    "import deepdish as dd\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "splitting = 'custom'\n",
    "data_setting = 'rawflt'\n",
    "model_setting = 'dl4tsc_inc'\n",
    "nb_classes = 2\n",
    "# clean = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{TEMP_DATADIR}/df_train_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_train = train.x.tolist()\n",
    "y_train = train.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(f\"{TEMP_DATADIR}/df_val_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_val = val.x.tolist()\n",
    "y_val = val.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{TEMP_DATADIR}/df_test_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_test = test.x.tolist()\n",
    "y_test = test.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "1    13610\n",
      "0     8244\n",
      "dtype: int64\n",
      "\n",
      "val: \n",
      "1    4568\n",
      "0    2717\n",
      "dtype: int64\n",
      "\n",
      "test: \n",
      "1    12337\n",
      "0     3139\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: \\n{pd.Series(y_train).value_counts()}\\n\")\n",
    "print(f\"val: \\n{pd.Series(y_val).value_counts()}\\n\")\n",
    "print(f\"test: \\n{pd.Series(y_test).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincf = TrainConfiguration(nb_classes=nb_classes, setting=data_setting,model_name=f\"Flies_{data_setting}_{model_setting}_{splitting}\", monitor='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ INPUT SHAPE:(5000, 1)\n",
      "/home/kalfasyan/projects/wingbeat_frequencies/temp_data/\n",
      "WARNING:tensorflow:From /home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Last 5 layers:\n",
      "batch_normalization_17\n",
      "activation_18\n",
      "global_average_pooling1d_1\n",
      "dense_1\n",
      "activation_19\n"
     ]
    }
   ],
   "source": [
    "modelconf = ModelConfiguration(model_setting=model_setting, data_setting=data_setting, nb_classes=nb_classes)\n",
    "model = modelconf.config\n",
    "print(\"Last 5 layers:\")\n",
    "for i in model.layers[-5:]:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.3254488112566716, 1: 0.8028655400440853}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {i : weights[i] for i in range(nb_classes)}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.3748 - acc: 0.8355\n",
      "Epoch 00001: val_acc improved from -inf to 0.43157, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 205s 300ms/step - loss: 0.3745 - acc: 0.8357 - val_loss: 1.5274 - val_acc: 0.4316\n",
      "Epoch 2/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9234\n",
      "Epoch 00002: val_acc improved from 0.43157 to 0.46328, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 194s 284ms/step - loss: 0.2073 - acc: 0.9234 - val_loss: 2.6175 - val_acc: 0.4633\n",
      "Epoch 3/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9396\n",
      "Epoch 00003: val_acc improved from 0.46328 to 0.72011, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 194s 284ms/step - loss: 0.1676 - acc: 0.9396 - val_loss: 1.2039 - val_acc: 0.7201\n",
      "Epoch 4/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9483\n",
      "Epoch 00004: val_acc improved from 0.72011 to 0.89101, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 196s 287ms/step - loss: 0.1448 - acc: 0.9483 - val_loss: 0.3438 - val_acc: 0.8910\n",
      "Epoch 5/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9530\n",
      "Epoch 00005: val_acc improved from 0.89101 to 0.94262, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 196s 287ms/step - loss: 0.1322 - acc: 0.9530 - val_loss: 0.1700 - val_acc: 0.9426\n",
      "Epoch 6/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9572\n",
      "Epoch 00006: val_acc improved from 0.94262 to 0.96774, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 195s 286ms/step - loss: 0.1215 - acc: 0.9573 - val_loss: 0.1107 - val_acc: 0.9677\n",
      "Epoch 7/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9602\n",
      "Epoch 00007: val_acc improved from 0.96774 to 0.96980, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 195s 285ms/step - loss: 0.1129 - acc: 0.9602 - val_loss: 0.0956 - val_acc: 0.9698\n",
      "Epoch 8/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9627\n",
      "Epoch 00008: val_acc did not improve from 0.96980\n",
      "683/683 [==============================] - 195s 286ms/step - loss: 0.1052 - acc: 0.9627 - val_loss: 0.1351 - val_acc: 0.9544\n",
      "Epoch 9/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9647\n",
      "Epoch 00009: val_acc did not improve from 0.96980\n",
      "683/683 [==============================] - 195s 285ms/step - loss: 0.0995 - acc: 0.9647 - val_loss: 0.1196 - val_acc: 0.9602\n",
      "Epoch 10/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9665\n",
      "Epoch 00010: val_acc did not improve from 0.96980\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "683/683 [==============================] - 196s 287ms/step - loss: 0.0925 - acc: 0.9665 - val_loss: 0.1355 - val_acc: 0.9574\n",
      "Epoch 11/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9755\n",
      "Epoch 00011: val_acc improved from 0.96980 to 0.97708, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 195s 286ms/step - loss: 0.0698 - acc: 0.9755 - val_loss: 0.0761 - val_acc: 0.9771\n",
      "Epoch 12/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9793\n",
      "Epoch 00012: val_acc improved from 0.97708 to 0.97831, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 196s 287ms/step - loss: 0.0606 - acc: 0.9794 - val_loss: 0.0709 - val_acc: 0.9783\n",
      "Epoch 13/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9807\n",
      "Epoch 00013: val_acc improved from 0.97831 to 0.97914, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 196s 287ms/step - loss: 0.0563 - acc: 0.9807 - val_loss: 0.0682 - val_acc: 0.9791\n",
      "Epoch 14/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9823\n",
      "Epoch 00014: val_acc improved from 0.97914 to 0.97927, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 196s 287ms/step - loss: 0.0529 - acc: 0.9823 - val_loss: 0.0662 - val_acc: 0.9793\n",
      "Epoch 15/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9833\n",
      "Epoch 00015: val_acc improved from 0.97927 to 0.97955, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 197s 288ms/step - loss: 0.0499 - acc: 0.9833 - val_loss: 0.0654 - val_acc: 0.9795\n",
      "Epoch 16/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9846\n",
      "Epoch 00016: val_acc did not improve from 0.97955\n",
      "683/683 [==============================] - 197s 288ms/step - loss: 0.0470 - acc: 0.9847 - val_loss: 0.0651 - val_acc: 0.9793\n",
      "Epoch 17/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9857\n",
      "Epoch 00017: val_acc did not improve from 0.97955\n",
      "683/683 [==============================] - 197s 289ms/step - loss: 0.0443 - acc: 0.9857 - val_loss: 0.0650 - val_acc: 0.9786\n",
      "Epoch 18/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9867\n",
      "Epoch 00018: val_acc did not improve from 0.97955\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "683/683 [==============================] - 197s 288ms/step - loss: 0.0417 - acc: 0.9867 - val_loss: 0.0651 - val_acc: 0.9783\n",
      "Epoch 19/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9885\n",
      "Epoch 00019: val_acc improved from 0.97955 to 0.98023, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 197s 289ms/step - loss: 0.0366 - acc: 0.9885 - val_loss: 0.0636 - val_acc: 0.9802\n",
      "Epoch 20/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9898\n",
      "Epoch 00020: val_acc did not improve from 0.98023\n",
      "683/683 [==============================] - 198s 289ms/step - loss: 0.0348 - acc: 0.9898 - val_loss: 0.0628 - val_acc: 0.9800\n",
      "Epoch 21/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9902\n",
      "Epoch 00021: val_acc did not improve from 0.98023\n",
      "683/683 [==============================] - 197s 289ms/step - loss: 0.0342 - acc: 0.9903 - val_loss: 0.0625 - val_acc: 0.9801\n",
      "Epoch 22/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9906\n",
      "Epoch 00022: val_acc did not improve from 0.98023\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "683/683 [==============================] - 198s 290ms/step - loss: 0.0337 - acc: 0.9906 - val_loss: 0.0623 - val_acc: 0.9802\n",
      "Epoch 23/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9905\n",
      "Epoch 00023: val_acc improved from 0.98023 to 0.98065, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "683/683 [==============================] - 197s 289ms/step - loss: 0.0330 - acc: 0.9905 - val_loss: 0.0629 - val_acc: 0.9806\n",
      "Epoch 24/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9908\n",
      "Epoch 00024: val_acc did not improve from 0.98065\n",
      "683/683 [==============================] - 197s 289ms/step - loss: 0.0329 - acc: 0.9908 - val_loss: 0.0627 - val_acc: 0.9802\n",
      "Epoch 25/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9908\n",
      "Epoch 00025: val_acc did not improve from 0.98065\n",
      "683/683 [==============================] - 198s 289ms/step - loss: 0.0328 - acc: 0.9908 - val_loss: 0.0626 - val_acc: 0.9802\n",
      "Epoch 26/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9909\n",
      "Epoch 00026: val_acc did not improve from 0.98065\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "683/683 [==============================] - 198s 290ms/step - loss: 0.0327 - acc: 0.9909 - val_loss: 0.0625 - val_acc: 0.9805\n",
      "Epoch 27/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9910\n",
      "Epoch 00027: val_acc did not improve from 0.98065\n",
      "683/683 [==============================] - 199s 291ms/step - loss: 0.0326 - acc: 0.9910 - val_loss: 0.0626 - val_acc: 0.9801\n",
      "Epoch 28/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9911\n",
      "Epoch 00028: val_acc did not improve from 0.98065\n",
      "683/683 [==============================] - 198s 290ms/step - loss: 0.0326 - acc: 0.9911 - val_loss: 0.0626 - val_acc: 0.9801\n",
      "Epoch 29/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9911\n",
      "Epoch 00029: val_acc did not improve from 0.98065\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "683/683 [==============================] - 199s 291ms/step - loss: 0.0325 - acc: 0.9911 - val_loss: 0.0626 - val_acc: 0.9802\n",
      "Epoch 30/100\n",
      "682/683 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9911\n",
      "Epoch 00030: val_acc did not improve from 0.98065\n",
      "683/683 [==============================] - 199s 291ms/step - loss: 0.0325 - acc: 0.9911 - val_loss: 0.0626 - val_acc: 0.9801\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_generator(X_train, y_train, \n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting,\n",
    "                                     preprocessing_train_stats=''),\n",
    "                    steps_per_epoch = int(math.ceil(float(len(X_train)) / float(traincf.batch_size))),\n",
    "                    epochs = traincf.epochs,\n",
    "                    validation_data = valid_generator(X_val, y_val,\n",
    "                                                        batch_size=traincf.batch_size,\n",
    "                                                        target_names=np.unique(y_test).tolist(),\n",
    "                                                        setting=traincf.setting,\n",
    "                                                         preprocessing_train_stats=''),\n",
    "                    validation_steps=int(math.ceil(float(len(X_val))/float(traincf.batch_size))),\n",
    "                    callbacks=traincf.callbacks_list,\n",
    "             class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(valid_generator(X_test, y_test,\n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting,\n",
    "                                  preprocessing_train_stats=''),\n",
    "                              steps=int(math.ceil(float(len(X_test))/float(traincf.batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.827838738074727"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "balanced_accuracy_score(y_true=y_test, y_pred=np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-18683cc3f293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=np.argmax(pred, axis=1))\n",
    "cm = cm.astype(np.float) / cm.astype(np.float).sum(axis=0)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='.2g')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0=melanogaster, 1=suzukii, 2=zaprionus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4483, 10993])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04146399, -2.43996216,  0.93576026])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = np.random.randn(2,3)\n",
    "np.sum(mat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2088636 , -1.95967012, -1.32818605],\n",
       "       [ 0.19686124,  0.73846658,  0.17136828]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12337\n",
       "0     3139\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "sub = pd.concat([pd.Series(y_test), pd.Series(X_test)], axis=1)\n",
    "sub['preds'] = y_pred\n",
    "sub.columns = ['labels','fnames','preds']\n",
    "sub['datestr'] = get_wingbeat_dates(sub.fnames)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(f'{TEMP_DATADIR}/df_{model_setting}_{data_setting}_{splitting}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
