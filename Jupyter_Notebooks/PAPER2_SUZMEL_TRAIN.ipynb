{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from wavhandler import *\n",
    "from configs import DatasetConfiguration\n",
    "from utils_train import *\n",
    "from configs import *\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, classification_report, make_scorer, log_loss\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, GlobalAveragePooling2D\n",
    "import seaborn as sb\n",
    "import deepdish as dd\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "splitting = 'custom'\n",
    "data_setting = 'rawflt'\n",
    "model_setting = 'dl4tsc_inc'\n",
    "nb_classes = 2\n",
    "# clean = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{TEMP_DATADIR}/df_train_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_train = train.x.tolist()\n",
    "y_train = train.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(f\"{TEMP_DATADIR}/df_val_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_val = val.x.tolist()\n",
    "y_val = val.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{TEMP_DATADIR}/df_test_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_test = test.x.tolist()\n",
    "y_test = test.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "0    14979\n",
      "1    13617\n",
      "dtype: int64\n",
      "\n",
      "val: \n",
      "0    4971\n",
      "1    4561\n",
      "dtype: int64\n",
      "\n",
      "test: \n",
      "0    18260\n",
      "1    12337\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: \\n{pd.Series(y_train).value_counts()}\\n\")\n",
    "print(f\"val: \\n{pd.Series(y_val).value_counts()}\\n\")\n",
    "print(f\"test: \\n{pd.Series(y_test).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincf = TrainConfiguration(nb_classes=nb_classes, setting=data_setting,model_name=f\"Flies_{data_setting}_{model_setting}_{splitting}\", monitor='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ INPUT SHAPE:(5000, 1)\n",
      "/home/kalfasyan/projects/wingbeat_frequencies/temp_data/\n",
      "WARNING:tensorflow:From /home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Last 5 layers:\n",
      "activation_18\n",
      "global_average_pooling1d_1\n",
      "dense_1\n",
      "dense_2\n",
      "activation_20\n"
     ]
    }
   ],
   "source": [
    "modelconf = ModelConfiguration(model_setting=model_setting, data_setting=data_setting, nb_classes=nb_classes)\n",
    "model = modelconf.config\n",
    "\n",
    "base_output = model.layers[-2].output\n",
    "new_output = Dense(1, activation=None)(base_output)\n",
    "new_output2 = Activation('sigmoid')(new_output)\n",
    "model = Model(inputs=model.inputs, outputs=new_output2)\n",
    "\n",
    "print(\"Last 5 layers:\")\n",
    "for i in model.layers[-5:]:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 5000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 5000, 1)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 5000, 32)     416         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5000, 32)     192         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 5000, 32)     96          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 5000, 32)     32          max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 5000, 128)    0           conv1d_36[0][0]                  \n",
      "                                                                 conv1d_37[0][0]                  \n",
      "                                                                 conv1d_38[0][0]                  \n",
      "                                                                 conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 5000, 128)    512         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 5000, 128)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 5000, 32)     4096        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 5000, 128)    0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5000, 32)     13312       conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 5000, 32)     6144        conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 5000, 32)     3072        conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 5000, 128)    0           conv1d_41[0][0]                  \n",
      "                                                                 conv1d_42[0][0]                  \n",
      "                                                                 conv1d_43[0][0]                  \n",
      "                                                                 conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 5000, 128)    512         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 5000, 128)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 5000, 32)     4096        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 5000, 128)    0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5000, 32)     13312       conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 5000, 32)     6144        conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 5000, 32)     3072        conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 5000, 128)    0           conv1d_46[0][0]                  \n",
      "                                                                 conv1d_47[0][0]                  \n",
      "                                                                 conv1d_48[0][0]                  \n",
      "                                                                 conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 5000, 128)    128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 5000, 128)    512         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 5000, 128)    512         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 5000, 128)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 5000, 128)    0           batch_normalization_12[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5000, 128)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 5000, 32)     4096        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 5000, 128)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5000, 32)     13312       conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 5000, 32)     6144        conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 5000, 32)     3072        conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 5000, 128)    0           conv1d_52[0][0]                  \n",
      "                                                                 conv1d_53[0][0]                  \n",
      "                                                                 conv1d_54[0][0]                  \n",
      "                                                                 conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 5000, 128)    512         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 5000, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 5000, 32)     4096        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 5000, 128)    0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 5000, 32)     13312       conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 5000, 32)     6144        conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5000, 32)     3072        conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 5000, 128)    0           conv1d_57[0][0]                  \n",
      "                                                                 conv1d_58[0][0]                  \n",
      "                                                                 conv1d_59[0][0]                  \n",
      "                                                                 conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 5000, 128)    512         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 5000, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 5000, 32)     4096        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 5000, 128)    0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 5000, 32)     13312       conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 5000, 32)     6144        conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 5000, 32)     3072        conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 5000, 128)    0           conv1d_62[0][0]                  \n",
      "                                                                 conv1d_63[0][0]                  \n",
      "                                                                 conv1d_64[0][0]                  \n",
      "                                                                 conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 5000, 128)    16384       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 5000, 128)    512         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 5000, 128)    512         conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 5000, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 5000, 128)    0           batch_normalization_16[0][0]     \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 5000, 128)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 5000, 32)     4096        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 5000, 128)    0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 5000, 32)     13312       conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 5000, 32)     6144        conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 5000, 32)     3072        conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 5000, 128)    0           conv1d_68[0][0]                  \n",
      "                                                                 conv1d_69[0][0]                  \n",
      "                                                                 conv1d_70[0][0]                  \n",
      "                                                                 conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 5000, 128)    512         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 5000, 128)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            3           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 206,437\n",
      "Trainable params: 204,133\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.9545363508912478, 1: 1.050011015642212}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {i : weights[i] for i in range(nb_classes)}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.3272 - acc: 0.8583\n",
      "Epoch 00001: val_acc improved from -inf to 0.73678, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 270s 302ms/step - loss: 0.3271 - acc: 0.8583 - val_loss: 0.5792 - val_acc: 0.7368\n",
      "Epoch 2/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.2377 - acc: 0.9052\n",
      "Epoch 00002: val_acc improved from 0.73678 to 0.83708, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 258s 288ms/step - loss: 0.2377 - acc: 0.9053 - val_loss: 0.4277 - val_acc: 0.8371\n",
      "Epoch 3/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.1890 - acc: 0.9277\n",
      "Epoch 00003: val_acc improved from 0.83708 to 0.90579, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 256s 287ms/step - loss: 0.1889 - acc: 0.9278 - val_loss: 0.2377 - val_acc: 0.9058\n",
      "Epoch 4/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9402\n",
      "Epoch 00004: val_acc did not improve from 0.90579\n",
      "894/894 [==============================] - 260s 291ms/step - loss: 0.1608 - acc: 0.9402 - val_loss: 0.9127 - val_acc: 0.6618\n",
      "Epoch 5/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9461\n",
      "Epoch 00005: val_acc improved from 0.90579 to 0.94692, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 257s 288ms/step - loss: 0.1449 - acc: 0.9461 - val_loss: 0.1426 - val_acc: 0.9469\n",
      "Epoch 6/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9511\n",
      "Epoch 00006: val_acc did not improve from 0.94692\n",
      "894/894 [==============================] - 254s 284ms/step - loss: 0.1338 - acc: 0.9511 - val_loss: 0.1874 - val_acc: 0.9314\n",
      "Epoch 7/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9538\n",
      "Epoch 00007: val_acc did not improve from 0.94692\n",
      "894/894 [==============================] - 255s 286ms/step - loss: 0.1248 - acc: 0.9538 - val_loss: 0.3340 - val_acc: 0.8799\n",
      "Epoch 8/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9569\n",
      "Epoch 00008: val_acc did not improve from 0.94692\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "894/894 [==============================] - 256s 286ms/step - loss: 0.1170 - acc: 0.9569 - val_loss: 0.5950 - val_acc: 0.8242\n",
      "Epoch 9/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9680\n",
      "Epoch 00009: val_acc improved from 0.94692 to 0.95615, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 256s 287ms/step - loss: 0.0900 - acc: 0.9680 - val_loss: 0.1159 - val_acc: 0.9561\n",
      "Epoch 10/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9719\n",
      "Epoch 00010: val_acc improved from 0.95615 to 0.96727, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 256s 286ms/step - loss: 0.0809 - acc: 0.9720 - val_loss: 0.0937 - val_acc: 0.9673\n",
      "Epoch 11/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9736\n",
      "Epoch 00011: val_acc improved from 0.96727 to 0.96748, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 256s 287ms/step - loss: 0.0764 - acc: 0.9736 - val_loss: 0.0928 - val_acc: 0.9675\n",
      "Epoch 12/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9748\n",
      "Epoch 00012: val_acc improved from 0.96748 to 0.96853, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 257s 287ms/step - loss: 0.0727 - acc: 0.9748 - val_loss: 0.0912 - val_acc: 0.9685\n",
      "Epoch 13/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9757\n",
      "Epoch 00013: val_acc improved from 0.96853 to 0.96863, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 257s 288ms/step - loss: 0.0693 - acc: 0.9757 - val_loss: 0.0913 - val_acc: 0.9686\n",
      "Epoch 14/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9767\n",
      "Epoch 00014: val_acc improved from 0.96863 to 0.96895, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 257s 287ms/step - loss: 0.0661 - acc: 0.9767 - val_loss: 0.0907 - val_acc: 0.9689\n",
      "Epoch 15/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9781\n",
      "Epoch 00015: val_acc did not improve from 0.96895\n",
      "894/894 [==============================] - 257s 288ms/step - loss: 0.0631 - acc: 0.9781 - val_loss: 0.0914 - val_acc: 0.9689\n",
      "Epoch 16/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9792\n",
      "Epoch 00016: val_acc did not improve from 0.96895\n",
      "894/894 [==============================] - 258s 289ms/step - loss: 0.0601 - acc: 0.9792 - val_loss: 0.0935 - val_acc: 0.9679\n",
      "Epoch 17/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9803\n",
      "Epoch 00017: val_acc did not improve from 0.96895\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "894/894 [==============================] - 257s 288ms/step - loss: 0.0573 - acc: 0.9803 - val_loss: 0.0959 - val_acc: 0.9661\n",
      "Epoch 18/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9824\n",
      "Epoch 00018: val_acc improved from 0.96895 to 0.97230, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 258s 288ms/step - loss: 0.0503 - acc: 0.9824 - val_loss: 0.0829 - val_acc: 0.9723\n",
      "Epoch 19/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9833\n",
      "Epoch 00019: val_acc improved from 0.97230 to 0.97272, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 258s 288ms/step - loss: 0.0489 - acc: 0.9833 - val_loss: 0.0826 - val_acc: 0.9727\n",
      "Epoch 20/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9837\n",
      "Epoch 00020: val_acc improved from 0.97272 to 0.97283, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 258s 289ms/step - loss: 0.0483 - acc: 0.9837 - val_loss: 0.0826 - val_acc: 0.9728\n",
      "Epoch 21/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9839\n",
      "Epoch 00021: val_acc did not improve from 0.97283\n",
      "894/894 [==============================] - 259s 290ms/step - loss: 0.0478 - acc: 0.9839 - val_loss: 0.0826 - val_acc: 0.9727\n",
      "Epoch 22/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9840\n",
      "Epoch 00022: val_acc did not improve from 0.97283\n",
      "894/894 [==============================] - 259s 289ms/step - loss: 0.0473 - acc: 0.9841 - val_loss: 0.0826 - val_acc: 0.9726\n",
      "Epoch 23/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9843\n",
      "Epoch 00023: val_acc did not improve from 0.97283\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "894/894 [==============================] - 259s 289ms/step - loss: 0.0468 - acc: 0.9843 - val_loss: 0.0827 - val_acc: 0.9728\n",
      "Epoch 24/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9848\n",
      "Epoch 00024: val_acc improved from 0.97283 to 0.97367, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 259s 289ms/step - loss: 0.0457 - acc: 0.9849 - val_loss: 0.0829 - val_acc: 0.9737\n",
      "Epoch 25/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9850\n",
      "Epoch 00025: val_acc improved from 0.97367 to 0.97377, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 259s 290ms/step - loss: 0.0456 - acc: 0.9850 - val_loss: 0.0829 - val_acc: 0.9738\n",
      "Epoch 26/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9850\n",
      "Epoch 00026: val_acc did not improve from 0.97377\n",
      "894/894 [==============================] - 259s 290ms/step - loss: 0.0455 - acc: 0.9850 - val_loss: 0.0829 - val_acc: 0.9737\n",
      "Epoch 27/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9851\n",
      "Epoch 00027: val_acc did not improve from 0.97377\n",
      "894/894 [==============================] - 259s 290ms/step - loss: 0.0455 - acc: 0.9851 - val_loss: 0.0829 - val_acc: 0.9736\n",
      "Epoch 28/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9851\n",
      "Epoch 00028: val_acc did not improve from 0.97377\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "894/894 [==============================] - 260s 291ms/step - loss: 0.0454 - acc: 0.9851 - val_loss: 0.0829 - val_acc: 0.9736\n",
      "Epoch 29/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9852\n",
      "Epoch 00029: val_acc did not improve from 0.97377\n",
      "894/894 [==============================] - 260s 291ms/step - loss: 0.0453 - acc: 0.9852 - val_loss: 0.0829 - val_acc: 0.9736\n",
      "Epoch 30/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9853\n",
      "Epoch 00030: val_acc did not improve from 0.97377\n",
      "894/894 [==============================] - 260s 291ms/step - loss: 0.0453 - acc: 0.9853 - val_loss: 0.0829 - val_acc: 0.9737\n",
      "Epoch 31/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9853\n",
      "Epoch 00031: val_acc did not improve from 0.97377\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "894/894 [==============================] - 260s 291ms/step - loss: 0.0452 - acc: 0.9853 - val_loss: 0.0829 - val_acc: 0.9737\n",
      "Epoch 32/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9853\n",
      "Epoch 00032: val_acc did not improve from 0.97377\n",
      "894/894 [==============================] - 260s 291ms/step - loss: 0.0452 - acc: 0.9853 - val_loss: 0.0829 - val_acc: 0.9737\n",
      "Epoch 00032: early stopping\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_generator(X_train, y_train, \n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting,\n",
    "                                     preprocessing_train_stats='', binary_labels=True),\n",
    "                    steps_per_epoch = int(math.ceil(float(len(X_train)) / float(traincf.batch_size))),\n",
    "                    epochs = traincf.epochs,\n",
    "                    validation_data = valid_generator(X_val, y_val,\n",
    "                                                        batch_size=traincf.batch_size,\n",
    "                                                        target_names=np.unique(y_test).tolist(),\n",
    "                                                        setting=traincf.setting,\n",
    "                                                         preprocessing_train_stats='', binary_labels=True),\n",
    "                    validation_steps=int(math.ceil(float(len(X_val))/float(traincf.batch_size))),\n",
    "                    callbacks=traincf.callbacks_list,\n",
    "             class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(valid_generator(X_test, y_test,\n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting,\n",
    "                                  preprocessing_train_stats='', binary_labels=True),\n",
    "                              steps=int(math.ceil(float(len(X_test))/float(traincf.batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(pred < 0.5, 0 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.883328016835704"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'actual')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "cm = cm.astype(np.float) / cm.astype(np.float).sum(axis=0)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='.2g')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8518275399769402"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "balanced_accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'actual')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD4CAYAAAAqw8chAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAWKUlEQVR4nO3deZwdZZno8d/TnYU1bB0SshASEjaVZUhAEERAIBlBRBEiDIxecyNc4SIwCrKpgMCMyjhoxhgYNgcMDIosJiwihjWYOINCAsEQlnRWIoFAyNan3/tHd8LpptN9+tLnnKrO7+unPnRVvV3nOX768/Dw1PtWRUoJSVK21VQ7AElSx0zWkpQDJmtJygGTtSTlgMlaknKgR7UD2JgH+o11moo+4Njlj1c7BGVQw9oF8WGvsW7ZvJJzTs+6YR/68zrLylqSciCzlbUkVVRjodoRtMtkLUkAhYZqR9Auk7UkASk1VjuEdpmsJQmg0WQtSdlnZS1JOeANRknKAStrScq+5GwQScoBbzBKUg7YBpGkHPAGoyTlgJW1JOWANxglKQe8wShJ2ZeSPWtJyj571pKUA7ZBJCkHrKwlKQcK66odQbtM1pIEtkEkKRdsg0hSDlhZS1IOmKwlKfuSNxglKQfsWUtSDtgGkaQcsLKWpBywspakHLCylqQcaPDlA5KUfVbWkpQD9qwlKQesrCUpB6ysJSkHrKwlKQcyPhukptoBSFImpFT61oGIGB0RcyJibkRc2Mb5bSLivoj4c0TMioivdHRNK2tJgi7rWUdELTABOAqoB2ZExL0ppdlFw74OzE4pHRcRfYE5EXFbSmntxq5rspYk6MobjAcAc1NK8wAiYjJwPFCcrBOwdUQEsBXwJtBuH8Y2iCRB0w3GEreIGB8RM4u28UVXGgjML9qvbz5W7KfAnsBC4DngnJTav8NpZS1JAIVCyUNTSpOASRs5HW39Sqv9Y4BngSOAXYGHI+LxlNKKjX2mlbUkQVMbpNStffXA4KL9QTRV0MW+Avw6NZkLvALs0d5FTdaSBF2ZrGcAIyJiaET0AsYC97Ya8zpwJEBE9AN2B+a1d1HbIJIEXbYoJqXUEBFnAQ8CtcCNKaVZEXFG8/mJwBXAzRHxHE1tkwtSSsvau67JWpKA1Njx/OmSr5XSFGBKq2MTi35eCBzdmWuarCUJfDaIJOVCJ2aDVIPJWpLAylqSciHjydqpe1VWd/g+HPrktRw6/ccMPfuzGx3XZ99hHLPwdvode+CGY4fN+Amf+MO/cPAj13DQg9+vRLgqk2OO/hSznn+MF2c/wbe++fU2x/zrtZfz4uwn+O8/Pcx++350w/HrJ/2IhfV/5tn/eaTF+H32+QhPPn4fM2c8xPSnpzBq5L5l/Q6514UPcioHk3U11QR7XfO/mHnKNTxx6PnsdMIn2HK31qtSm8btfukpLHv0zx849cfPX8FTR17I08dcXIGAVQ41NTVc92/f59jj/oGP7XM4J5/8Ofbcc0SLMWNGH8GI4UPZY69DOPPMC5jw06s3nLv11jv5zLGnfuC611x1MVdceS0jRx3N9773Q6652r+RdnXdPOuyKFuyjog9IuKCiLguIv6t+ec9y/V5ebTt3w3nvVcWs+q1paR1BRb/5in6jR75gXFDxo1myf1/ZO2yja5EVY4dMGo/Xn75VV555XXWrVvHnXfew2ePO6bFmOOOO4Zf3HYXAM/88b/ZZttt6N9/RwAef+IZ3lz+1geum1Ji6z5bA9Bnm61ZuGhJmb9JzjWm0rcqKEuyjogLgMk0Tfb+I00regL4ZVvPdt1U9e6/PasW/m3D/uqFb9K7//atxmxHvzGjeP2Whz/w+4nEyDsu4qCHrmLQaUeWPV6Vx4CB/Zlf//5q5PoFixgwoH+LMQMH9Kd+/vtjFtQvYmCrMa2d90/f4Z+vvoRXXp7Bv1xzKRdfcnW74zd5hULpWxWU6wbjV4GPpJTWFR+MiGuBWcA1bf1S85OrxgOcvfVI/n7zXcsUXka09biXVs972fOKf2TOlbe3+W/zZ479DmuWLKdXXR9G3nkxK/+6gOXTXyxPrCqbpqdktpRa9UVLGdPa18afzvnf/C533z2FE088jut//iOOGTP2wwXbjaWM32AsV7JuBAYAr7U6vlPzuTYVP8nqgX5jq/PfGhW0ZtGbbD5ghw37mw3YnjWLl7cY02ffYew78RwAeu6wNXWf3pdUKLB06kzWLGkau3bZCpZOmcE2+w03WefQgvpFDB40YMP+oIE7sahVy6J+wSIGDX5/zMBBO3XY1jj9tC9y7nmXAXDXXfcxaeIPujDqbqhK7Y1Slatn/Q3gkYiYGhGTmrcHgEeAc8r0mbnz9v+8zBbD+rP5zn2JnrX0/9zBLH3wTy3GPDbq/zJt1NlMG3U2S+57htkX3MjSqTOp3aI3tVtuBkDtFr3Z4VN78+6L89v6GGXcjJnPMnz4UHbZZTA9e/bkpJOO5777H2ox5v77H+K0U08E4MAD/o4Vb69g8eKl7V534aIlHPbJgwA44vBD+OvcV8rzBbqLTjzPuhrKUlmnlB6IiN1oemPCQJr+g78emJFSyvYyoQpKhUZmf/smRk6+iKitof6Xj/LunHoGn/5pAObf+ruN/m6vvtuw303nAxC1NSy6+8k2Z4so+wqFAud84xKm/PZ2amtquPmWO5g9+yXG/+/TAJh0/S+YMvURRo8+gjkvPMl7q1Yxbtx5G37/P38xgcM+eRB1ddvz6ryZfO/yH3LTzZM544xvcu21l9OjRw/WrF7NmWd+q1pfMR8yXllHR32vatkU2iDqvGOXP17tEJRBDWsXtHkHqDNWXlZ6ztny8skf+vM6yxWMkgRVa2+UymQtSZD5NojJWpLYdKfuSVK+WFlLUg6YrCUpB3z5gCRlX1e+g7EcTNaSBLZBJCkXnA0iSTlgZS1JOWCylqTsSwXbIJKUfVbWkpR9Tt2TpDwwWUtSDmS7ZW2yliSA1JDtbG2yliSwspakPPAGoyTlgZW1JGWflbUk5YGVtSRlX2qodgTtq6l2AJKUBamx9K0jETE6IuZExNyIuHAjYz4VEc9GxKyImNbRNa2sJQm6rA0SEbXABOAooB6YERH3ppRmF43ZFvh3YHRK6fWI2LGj61pZSxJdWlkfAMxNKc1LKa0FJgPHtxpzCvDrlNLrACmlpR1d1GQtSXRpsh4IzC/ar28+Vmw3YLuI+ENE/CkiTu/oorZBJAlIhSh5bESMB8YXHZqUUpq0/nRbl2+13wPYHzgS2Bx4OiKmp5Re2thnmqwlidJuHG4Y25SYJ23kdD0wuGh/ELCwjTHLUkorgZUR8RiwD7DRZG0bRJKA1Bglbx2YAYyIiKER0QsYC9zbasw9wKER0SMitgAOBF5o76JW1pJE5yrrdq+TUkNEnAU8CNQCN6aUZkXEGc3nJ6aUXoiIB4C/0DQP5YaU0vPtXddkLUlASqX3rDu+VpoCTGl1bGKr/R8APyj1miZrSaLrKutyMVlLEtDYidkg1WCyliQo5cZhVZmsJQmTtSTlQsr246zbT9YR8Q4fXHkDTSt0UkqpT1mikqQKy3VlnVLaulKBSFI1deXUvXLoVBuk+TF+m63fX//EKEnKu0LGZ4OUtNw8Ij4bEX8FXgGmAa8CU8sYlyRVVEpR8lYNpT4b5Arg48BLKaWhND0p6smyRSVJFdaFzwYpi1KT9bqU0t+AmoioSSk9CuxbxrgkqaJSKn2rhlJ71m9FxFbAY8BtEbEUyPjrJSWpdLmeDVLkeGA1cC5wKrANcHm5gpKkSis0ZvuJ0SUl6+YHZK93S5likaSqyfWimPVaLY7pBfQEVrooRlJ30dgd5lm3XhwTEZ+j6Q2+ktQtZH1RzP9Xkyal9BvgiC6ORZKqplvMBomIzxft1gAjafuZIV1m+A7Ly3l55dSqWY9XOwR1U92iDQIcV/RzA00rGI/v8mgkqUq6xWwQml7m2GLFYkR8Alja9SFJUuVlfDJIyT3rn5R4TJJyqTFFyVs1dPQ864OAg4G+EXFe0ak+NL1iXZK6hazPBumoDdIL2Kp5XPH0vRXAieUKSpIqLeMvN+/w5QPTgGkRcXNK6bUKxSRJFZfIdmVdas/6hojYdv1ORGwXEQ+WKSZJqriGFCVv1VDqbJC6lNJb63dSSsub3xojSd1Cd6msGyNi5/U7EbEL2Z/pIkkla+zEVg2lVtYXA09ExLTm/U8C48sTkiRVXtYr61If5PRARIykKUE/C9wDrCpnYJJUSbmeDbJeRIwDzgEG0ZSsPw48jQ9zktRNFDJeWZfasz4HGAW8llI6HNgPeKNsUUlShTVG6Vs1lNqzXp1SWh0RRETvlNKLEbF7WSOTpApqzHhlXWqyrm+eZ/0b4OGIWA4sLF9YklRZWZ/eVuoNxhOaf/xuRDxK0wtzHyhbVJJUYd3iBmOx5iXoktStNEb3aINIUrdWqHYAHcj2qxEkqUK6cjZIRIyOiDkRMTciLmxn3KiIKEREh08xtbKWJLpuNkhE1AITgKOAemBGRNybUprdxrh/Bkp6KJ6VtSTRNBuk1K0DBwBzU0rzUkprgcm0/c7as4FfUeLrEU3WkkSXtkEGAvOL9uubj20QEQOBE4CJpcZnspYkOvfUvYgYHxEzi7biB9u1lc5bF+Q/Bi5IKZV8X9OetSQBhU60rFNKk4BJGzldDwwu2h/EBxcRjgQmR9N0wTrg7yOiIaX0m419pslakujSRTEzgBERMRRYAIwFTikekFIauv7niLgZuL+9RA0ma0kCui5Zp5QaIuIsmmZ51AI3ppRmRcQZzedL7lMXM1lLEtCVr1ZMKU0BprQ61maSTil9uZRrmqwliW74bBBJ6o6yvtzcZC1JVO+lAqUyWUsStkEkKRdM1pKUA93iTTGS1N3Zs5akHHA2iCTlQGPGGyEma0nCG4ySlAvZrqtN1pIEWFlLUi40RLZra5O1JGEbRJJywTaIJOWAU/ckKQeynapN1pIE2AaRpFwoZLy2NllLElbWkpQLycpakrLPylrt2uKQkdR9+wyorWXFXVN564Y7W5zffNTe9P/pd2lYsBiAdx9+kuU/uw2AIQ/fQuPKVdDYSGooUH/S2RWPX+XxxPSZXPPjiRQaG/nCcaMZd9pJLc6/veIdLr36X5m/YBG9e/XiiovOZcSwXQC4dfLd/Oq+B4gIRuy6C1dedB69e/eqwrfIF6fuaeNqauh7yddZMO7bNCxZxuA7fsLKR6ez7uXXWwxb/afnWfR/LmvzEgu+/C0a31pRiWhVIYVCgSt/NIHrf3wV/Xes4+Rx53D4IQey69AhG8Zcf+sd7DFiV667+jLmvTaf7/9oAv9x3TUseWMZt911D/fc9nM2692b8y+9iqm/m8bnPnNUFb9RPmQ7VUNNtQPYlG32sd1Z9/pCGuoXw7oG3p36B7Y64qBqh6Uqe+6Fl9h50AAGD9yJnj17MubIw/j949NbjHn51df5+P77ADBsyGAWLFrCsjeXA9BQKLBmzVoaGgqsWr2GvnXbV/w75FEDqeStGkzWVVTbbwfWLX5jw37D4mXU7lj3gXGb7bsng3/9M3b6+ZX0Gv5+dUWCATdcxaD/+il9vjimEiGrApa+sYz+O/bdsN9vxzqWvvG3FmN2Hz6M3017CoDnZs9h0ZKlLFm6jH596/jyl77Apz9/Oocffwpbb7kFnzhw/4rGn1epE/+rhoon64j4SjvnxkfEzIiYOXl5fSXDqo5o66VvLf8QVs+ey6ufPo35nz+Tt2+7h/4/+c6Gc/Wnnkv9iWex6GsXs82XPstm+3+0zAGrElIbuaD1n8q4077Iinfe5Qv/+HVuu+te9hixK7W1tby94h0efXw6D/7XTfz+nttYtXoN9z34+8oEnnONndiqoRqV9fc2diKlNCmlNDKlNHLsdoMqGVNVFBYvo2f/9yuoHv3rKCxtWUGlle+R3lsNwHuPzSB61FKzbZ+m33/jzaZ/vvk2Kx95ks323qNCkauc+u1Yx+Kl7/8X15Kly+hbt0OLMVttuSVXXnwev7plAldf+k8sf+ttBg3ox/SZzzJwQD+2325bevbowZGHHcyzz82u9FfIpU2yso6Iv2xkew7oV47PzKPVz8+h55CB9BjYD3r2YKsxn2Lloy17k7V12234uffHdoeaGhrfWkFs3pvYYnMAYvPebH7w/qz966uVDF9l8tE9duP1+oXUL1zMunXrmPrINA4/5OMtxqx4513WrVsHwK/ue4D99/0YW225JTv168tfnn+RVatXk1LimZnPMmzI4Gp8jdzJemVdrtkg/YBjgOWtjgfwVJk+M38Kjbzx/QkMuP4qoqaGFXc/xNq5r9Hn5M8AsOKO37LV0YfSZ+yx0FAgrVnDkvOvBqB2h+3Y6brmlkiPWt797aO898TMan0TdaEePWq56Nwz+dp5l1AoFDjh2KMZPmwId9z9WwBOPuEzzHttPhdd8UNqa2oYtsvOXP7tbwCw90f24KjDD+Gkr5xNbW0te+y2K1883vsZpSi01X/KkEhlCDAi/gO4KaX0RBvnbk8pndLRNebudUy2/59TVQx57GfVDkEZ1LNuWFs3gDrllCEnlJxzbn/t7g/9eZ1Vlso6pfTVds51mKglqdJcbi5JOeByc0nKAZebS1IO2AaRpBzI+mwQk7Ukkf02iM8GkSS6dlFMRIyOiDkRMTciLmzj/KlFiwWfioh9OrqmlbUk0XU964ioBSYARwH1wIyIuDelVLzu/xXgsJTS8ogYA0wCDmzvuiZrSaJL2yAHAHNTSvMAImIycDywIVmnlIpXck8HOnwYkm0QSQJSSiVvxU8Ibd7GF11qIDC/aL+++djGfBWY2lF8VtaSBBQ6UVmnlCbR1LpoS8fPPl4/MOJwmpL1IR19pslakujSNkg9UPyow0HAwtaDImJv4AZgTErpb63Pt2YbRJLoXBukAzOAERExNCJ6AWOBe4sHRMTOwK+B01JKL5USn5W1JNF1lXVKqSEizgIeBGqBG1NKsyLijObzE4HLgB2Af4+m1wA1pJRGtnddk7Uk0bXLzVNKU4AprY5NLPp5HDCuM9c0WUsSLjeXpFzI+nJzk7UkYbKWpFwoxysOu5LJWpKwspakXPDlA5KUA4WU7bcwmqwlCXvWkpQL9qwlKQfsWUtSDjTaBpGk7LOylqQccDaIJOWAbRBJygHbIJKUA1bWkpQDVtaSlAOFVKh2CO0yWUsSLjeXpFxwubkk5YCVtSTlgLNBJCkHnA0iSTngcnNJygF71pKUA/asJSkHrKwlKQecZy1JOWBlLUk54GwQScoBbzBKUg7YBpGkHHAFoyTlgJW1JOVA1nvWkfV/mwgiYnxKaVK141C2+HexaampdgAqyfhqB6BM8u9iE2KylqQcMFlLUg6YrPPBvqTa4t/FJsQbjJKUA1bWkpQDJmtJygGTdcZFxOiImBMRcyPiwmrHo+qLiBsjYmlEPF/tWFQ5JusMi4haYAIwBtgL+FJE7FXdqJQBNwOjqx2EKstknW0HAHNTSvNSSmuBycDxVY5JVZZSegx4s9pxqLJM1tk2EJhftF/ffEzSJsZknW3RxjHnWkqbIJN1ttUDg4v2BwELqxSLpCoyWWfbDGBERAyNiF7AWODeKsckqQpM1hmWUmoAzgIeBF4A7kwpzapuVKq2iPgl8DSwe0TUR8RXqx2Tys/l5pKUA1bWkpQDJmtJygGTtSTlgMlaknLAZC1JOWCylqQcMFlLUg78PzyyUaFTGN5RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "cm = cm.astype(np.float) / cm.astype(np.float).sum(axis=0)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='.2g')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0=melanogaster, 1=suzukii, 2=zaprionus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "sub = pd.concat([pd.Series(y_test), pd.Series(X_test)], axis=1)\n",
    "sub['preds'] = y_pred\n",
    "sub.columns = ['labels','fnames','preds']\n",
    "sub['datestr'] = get_wingbeat_dates(sub.fnames)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(f'{TEMP_DATADIR}/df_{model_setting}_{data_setting}_{splitting}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
