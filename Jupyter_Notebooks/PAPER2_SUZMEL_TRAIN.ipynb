{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from wavhandler import *\n",
    "from configs import DatasetConfiguration\n",
    "from utils_train import *\n",
    "from configs import *\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, classification_report, make_scorer, log_loss\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, GlobalAveragePooling2D\n",
    "import seaborn as sb\n",
    "import deepdish as dd\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "splitting = 'custom'\n",
    "data_setting = 'rawflt'\n",
    "model_setting = 'dl4tsc_inc'\n",
    "nb_classes = 2\n",
    "# clean = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{TEMP_DATADIR}/df_train_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_train = train.x.tolist()\n",
    "y_train = train.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(f\"{TEMP_DATADIR}/df_val_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_val = val.x.tolist()\n",
    "y_val = val.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{TEMP_DATADIR}/df_test_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_test = test.x.tolist()\n",
    "y_test = test.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "0    14979\n",
      "1    13617\n",
      "dtype: int64\n",
      "\n",
      "val: \n",
      "0    4971\n",
      "1    4561\n",
      "dtype: int64\n",
      "\n",
      "test: \n",
      "1    12337\n",
      "0     2473\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: \\n{pd.Series(y_train).value_counts()}\\n\")\n",
    "print(f\"val: \\n{pd.Series(y_val).value_counts()}\\n\")\n",
    "print(f\"test: \\n{pd.Series(y_test).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincf = TrainConfiguration(nb_classes=nb_classes, setting=data_setting,model_name=f\"Flies_{data_setting}_{model_setting}_{splitting}\", monitor='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ INPUT SHAPE:(5000, 1)\n",
      "/home/kalfasyan/projects/wingbeat_frequencies/temp_data/\n",
      "WARNING:tensorflow:From /home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Last 5 layers:\n",
      "activation_18\n",
      "global_average_pooling1d_1\n",
      "dense_1\n",
      "dense_2\n",
      "activation_20\n"
     ]
    }
   ],
   "source": [
    "modelconf = ModelConfiguration(model_setting=model_setting, data_setting=data_setting, nb_classes=nb_classes)\n",
    "model = modelconf.config\n",
    "\n",
    "base_output = model.layers[-2].output\n",
    "new_output = Dense(1, activation=None)(base_output)\n",
    "new_output2 = Activation('sigmoid')(new_output)\n",
    "model = Model(inputs=model.inputs, outputs=new_output2)\n",
    "\n",
    "print(\"Last 5 layers:\")\n",
    "for i in model.layers[-5:]:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 5000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 5000, 1)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 5000, 32)     416         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5000, 32)     192         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 5000, 32)     96          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 5000, 32)     32          max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 5000, 128)    0           conv1d_36[0][0]                  \n",
      "                                                                 conv1d_37[0][0]                  \n",
      "                                                                 conv1d_38[0][0]                  \n",
      "                                                                 conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 5000, 128)    512         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 5000, 128)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 5000, 32)     4096        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 5000, 128)    0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5000, 32)     13312       conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 5000, 32)     6144        conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 5000, 32)     3072        conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 5000, 128)    0           conv1d_41[0][0]                  \n",
      "                                                                 conv1d_42[0][0]                  \n",
      "                                                                 conv1d_43[0][0]                  \n",
      "                                                                 conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 5000, 128)    512         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 5000, 128)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 5000, 32)     4096        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 5000, 128)    0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5000, 32)     13312       conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 5000, 32)     6144        conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 5000, 32)     3072        conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 5000, 128)    0           conv1d_46[0][0]                  \n",
      "                                                                 conv1d_47[0][0]                  \n",
      "                                                                 conv1d_48[0][0]                  \n",
      "                                                                 conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 5000, 128)    128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 5000, 128)    512         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 5000, 128)    512         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 5000, 128)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 5000, 128)    0           batch_normalization_12[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5000, 128)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 5000, 32)     4096        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 5000, 128)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5000, 32)     13312       conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 5000, 32)     6144        conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 5000, 32)     3072        conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 5000, 128)    0           conv1d_52[0][0]                  \n",
      "                                                                 conv1d_53[0][0]                  \n",
      "                                                                 conv1d_54[0][0]                  \n",
      "                                                                 conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 5000, 128)    512         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 5000, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 5000, 32)     4096        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 5000, 128)    0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 5000, 32)     13312       conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 5000, 32)     6144        conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5000, 32)     3072        conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 5000, 128)    0           conv1d_57[0][0]                  \n",
      "                                                                 conv1d_58[0][0]                  \n",
      "                                                                 conv1d_59[0][0]                  \n",
      "                                                                 conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 5000, 128)    512         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 5000, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 5000, 32)     4096        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 5000, 128)    0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 5000, 32)     13312       conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 5000, 32)     6144        conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 5000, 32)     3072        conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 5000, 128)    0           conv1d_62[0][0]                  \n",
      "                                                                 conv1d_63[0][0]                  \n",
      "                                                                 conv1d_64[0][0]                  \n",
      "                                                                 conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 5000, 128)    16384       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 5000, 128)    512         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 5000, 128)    512         conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 5000, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 5000, 128)    0           batch_normalization_16[0][0]     \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 5000, 128)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 5000, 32)     4096        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 5000, 128)    0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 5000, 32)     13312       conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 5000, 32)     6144        conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 5000, 32)     3072        conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 5000, 128)    0           conv1d_68[0][0]                  \n",
      "                                                                 conv1d_69[0][0]                  \n",
      "                                                                 conv1d_70[0][0]                  \n",
      "                                                                 conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 5000, 128)    512         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 5000, 128)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            3           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 206,437\n",
      "Trainable params: 204,133\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.9545363508912478, 1: 1.050011015642212}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {i : weights[i] for i in range(nb_classes)}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.3316 - acc: 0.8592\n",
      "Epoch 00001: val_acc improved from -inf to 0.74339, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 302s 338ms/step - loss: 0.3316 - acc: 0.8593 - val_loss: 0.7485 - val_acc: 0.7434\n",
      "Epoch 2/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.2309 - acc: 0.9067\n",
      "Epoch 00002: val_acc improved from 0.74339 to 0.87337, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 255s 286ms/step - loss: 0.2308 - acc: 0.9067 - val_loss: 0.2762 - val_acc: 0.8734\n",
      "Epoch 3/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9310\n",
      "Epoch 00003: val_acc improved from 0.87337 to 0.93789, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 256s 286ms/step - loss: 0.1804 - acc: 0.9310 - val_loss: 0.1717 - val_acc: 0.9379\n",
      "Epoch 4/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9417\n",
      "Epoch 00004: val_acc did not improve from 0.93789\n",
      "894/894 [==============================] - 254s 284ms/step - loss: 0.1569 - acc: 0.9417 - val_loss: 0.1759 - val_acc: 0.9367\n",
      "Epoch 5/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9465\n",
      "Epoch 00005: val_acc did not improve from 0.93789\n",
      "894/894 [==============================] - 254s 284ms/step - loss: 0.1439 - acc: 0.9465 - val_loss: 0.4310 - val_acc: 0.8539\n",
      "Epoch 6/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9501\n",
      "Epoch 00006: val_acc did not improve from 0.93789\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "894/894 [==============================] - 255s 285ms/step - loss: 0.1342 - acc: 0.9501 - val_loss: 0.7631 - val_acc: 0.7957\n",
      "Epoch 7/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9641\n",
      "Epoch 00007: val_acc improved from 0.93789 to 0.96727, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 255s 285ms/step - loss: 0.1031 - acc: 0.9641 - val_loss: 0.0967 - val_acc: 0.9673\n",
      "Epoch 8/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9664\n",
      "Epoch 00008: val_acc improved from 0.96727 to 0.96905, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 255s 285ms/step - loss: 0.0950 - acc: 0.9665 - val_loss: 0.0932 - val_acc: 0.9691\n",
      "Epoch 9/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9675\n",
      "Epoch 00009: val_acc improved from 0.96905 to 0.96937, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 255s 285ms/step - loss: 0.0904 - acc: 0.9675 - val_loss: 0.0917 - val_acc: 0.9694\n",
      "Epoch 10/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9695\n",
      "Epoch 00010: val_acc did not improve from 0.96937\n",
      "894/894 [==============================] - 256s 286ms/step - loss: 0.0864 - acc: 0.9695 - val_loss: 0.0908 - val_acc: 0.9694\n",
      "Epoch 11/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9705\n",
      "Epoch 00011: val_acc did not improve from 0.96937\n",
      "894/894 [==============================] - 255s 286ms/step - loss: 0.0828 - acc: 0.9706 - val_loss: 0.0905 - val_acc: 0.9694\n",
      "Epoch 12/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9714\n",
      "Epoch 00012: val_acc did not improve from 0.96937\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "894/894 [==============================] - 255s 286ms/step - loss: 0.0795 - acc: 0.9715 - val_loss: 0.0906 - val_acc: 0.9686\n",
      "Epoch 13/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9747\n",
      "Epoch 00013: val_acc improved from 0.96937 to 0.97262, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 256s 286ms/step - loss: 0.0719 - acc: 0.9748 - val_loss: 0.0839 - val_acc: 0.9726\n",
      "Epoch 14/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9753\n",
      "Epoch 00014: val_acc did not improve from 0.97262\n",
      "894/894 [==============================] - 256s 286ms/step - loss: 0.0708 - acc: 0.9753 - val_loss: 0.0836 - val_acc: 0.9726\n",
      "Epoch 15/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9750\n",
      "Epoch 00015: val_acc did not improve from 0.97262\n",
      "894/894 [==============================] - 256s 286ms/step - loss: 0.0701 - acc: 0.9750 - val_loss: 0.0834 - val_acc: 0.9724\n",
      "Epoch 16/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9754\n",
      "Epoch 00016: val_acc did not improve from 0.97262\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "894/894 [==============================] - 256s 287ms/step - loss: 0.0696 - acc: 0.9755 - val_loss: 0.0832 - val_acc: 0.9724\n",
      "Epoch 17/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9765\n",
      "Epoch 00017: val_acc improved from 0.97262 to 0.97293, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "894/894 [==============================] - 257s 287ms/step - loss: 0.0685 - acc: 0.9765 - val_loss: 0.0831 - val_acc: 0.9729\n",
      "Epoch 18/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9766\n",
      "Epoch 00018: val_acc did not improve from 0.97293\n",
      "894/894 [==============================] - 257s 287ms/step - loss: 0.0684 - acc: 0.9766 - val_loss: 0.0830 - val_acc: 0.9729\n",
      "Epoch 19/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9766\n",
      "Epoch 00019: val_acc did not improve from 0.97293\n",
      "894/894 [==============================] - 257s 288ms/step - loss: 0.0683 - acc: 0.9766 - val_loss: 0.0830 - val_acc: 0.9729\n",
      "Epoch 20/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9766\n",
      "Epoch 00020: val_acc did not improve from 0.97293\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "894/894 [==============================] - 258s 288ms/step - loss: 0.0683 - acc: 0.9766 - val_loss: 0.0829 - val_acc: 0.9729\n",
      "Epoch 21/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9766\n",
      "Epoch 00021: val_acc did not improve from 0.97293\n",
      "894/894 [==============================] - 258s 288ms/step - loss: 0.0681 - acc: 0.9766 - val_loss: 0.0830 - val_acc: 0.9728\n",
      "Epoch 22/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9766\n",
      "Epoch 00022: val_acc did not improve from 0.97293\n",
      "894/894 [==============================] - 258s 289ms/step - loss: 0.0681 - acc: 0.9766 - val_loss: 0.0830 - val_acc: 0.9728\n",
      "Epoch 23/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9766\n",
      "Epoch 00023: val_acc did not improve from 0.97293\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "894/894 [==============================] - 257s 288ms/step - loss: 0.0681 - acc: 0.9766 - val_loss: 0.0830 - val_acc: 0.9728\n",
      "Epoch 24/100\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9766\n",
      "Epoch 00024: val_acc did not improve from 0.97293\n",
      "894/894 [==============================] - 258s 289ms/step - loss: 0.0681 - acc: 0.9766 - val_loss: 0.0830 - val_acc: 0.9729\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_generator(X_train, y_train, \n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting,\n",
    "                                     preprocessing_train_stats='', binary_labels=True),\n",
    "                    steps_per_epoch = int(math.ceil(float(len(X_train)) / float(traincf.batch_size))),\n",
    "                    epochs = traincf.epochs,\n",
    "                    validation_data = valid_generator(X_val, y_val,\n",
    "                                                        batch_size=traincf.batch_size,\n",
    "                                                        target_names=np.unique(y_test).tolist(),\n",
    "                                                        setting=traincf.setting,\n",
    "                                                         preprocessing_train_stats='', binary_labels=True),\n",
    "                    validation_steps=int(math.ceil(float(len(X_val))/float(traincf.batch_size))),\n",
    "                    callbacks=traincf.callbacks_list,\n",
    "             class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(valid_generator(X_test, y_test,\n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting,\n",
    "                                  preprocessing_train_stats='', binary_labels=True),\n",
    "                              steps=int(math.ceil(float(len(X_test))/float(traincf.batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(pred < 0.5, 0 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8518275399769402"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "balanced_accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'actual')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "cm = cm.astype(np.float) / cm.astype(np.float).sum(axis=0)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='.2g')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0=melanogaster, 1=suzukii, 2=zaprionus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "sub = pd.concat([pd.Series(y_test), pd.Series(X_test)], axis=1)\n",
    "sub['preds'] = y_pred\n",
    "sub.columns = ['labels','fnames','preds']\n",
    "sub['datestr'] = get_wingbeat_dates(sub.fnames)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(f'{TEMP_DATADIR}/df_{model_setting}_{data_setting}_{splitting}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
