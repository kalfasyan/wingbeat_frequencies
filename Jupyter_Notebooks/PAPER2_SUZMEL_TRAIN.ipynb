{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from wavhandler import *\n",
    "from configs import DatasetConfiguration\n",
    "from utils_train import *\n",
    "from configs import *\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, classification_report, make_scorer, log_loss\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, GlobalAveragePooling2D\n",
    "import seaborn as sb\n",
    "import deepdish as dd\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "splitting = 'custom'\n",
    "data_setting = 'rawflt'\n",
    "model_setting = 'dl4tsc_inc'\n",
    "nb_classes = 2\n",
    "# clean = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{TEMP_DATADIR}/df_train_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_train = train.x.tolist()\n",
    "y_train = train.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(f\"{TEMP_DATADIR}/df_val_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_val = val.x.tolist()\n",
    "y_val = val.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{TEMP_DATADIR}/df_test_{data_setting}_{splitting}.csv\", index_col=False)\n",
    "X_test = test.x.tolist()\n",
    "y_test = test.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "0    13753\n",
      "1    13650\n",
      "dtype: int64\n",
      "\n",
      "val: \n",
      "0    4607\n",
      "1    4528\n",
      "dtype: int64\n",
      "\n",
      "test: \n",
      "1    12337\n",
      "0     3139\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: \\n{pd.Series(y_train).value_counts()}\\n\")\n",
    "print(f\"val: \\n{pd.Series(y_val).value_counts()}\\n\")\n",
    "print(f\"test: \\n{pd.Series(y_test).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincf = TrainConfiguration(nb_classes=nb_classes, setting=data_setting,model_name=f\"Flies_{data_setting}_{model_setting}_{splitting}\", monitor='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ INPUT SHAPE:(5000, 1)\n",
      "/home/kalfasyan/projects/wingbeat_frequencies/temp_data/\n",
      "WARNING:tensorflow:From /home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Last 5 layers:\n",
      "batch_normalization_17\n",
      "activation_18\n",
      "global_average_pooling1d_1\n",
      "dense_1\n",
      "activation_19\n"
     ]
    }
   ],
   "source": [
    "modelconf = ModelConfiguration(model_setting=model_setting, data_setting=data_setting, nb_classes=nb_classes)\n",
    "model = modelconf.config\n",
    "\n",
    "base_output = model.layers[-2].output\n",
    "new_output = Dense(1, activation=None)(base_output)\n",
    "new_output2 = Activation('sigmoid')(new_output)\n",
    "model = Model(inputs=model.inputs, outputs=new_output2)\n",
    "\n",
    "print(\"Last 5 layers:\")\n",
    "for i in model.layers[-5:]:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 5000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 5000, 1)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 5000, 32)     416         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5000, 32)     192         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 5000, 32)     96          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 5000, 32)     32          max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 5000, 128)    0           conv1d_36[0][0]                  \n",
      "                                                                 conv1d_37[0][0]                  \n",
      "                                                                 conv1d_38[0][0]                  \n",
      "                                                                 conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 5000, 128)    512         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 5000, 128)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 5000, 32)     4096        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 5000, 128)    0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5000, 32)     13312       conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 5000, 32)     6144        conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 5000, 32)     3072        conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 5000, 128)    0           conv1d_41[0][0]                  \n",
      "                                                                 conv1d_42[0][0]                  \n",
      "                                                                 conv1d_43[0][0]                  \n",
      "                                                                 conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 5000, 128)    512         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 5000, 128)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 5000, 32)     4096        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 5000, 128)    0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5000, 32)     13312       conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 5000, 32)     6144        conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 5000, 32)     3072        conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 5000, 128)    0           conv1d_46[0][0]                  \n",
      "                                                                 conv1d_47[0][0]                  \n",
      "                                                                 conv1d_48[0][0]                  \n",
      "                                                                 conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 5000, 128)    128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 5000, 128)    512         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 5000, 128)    512         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 5000, 128)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 5000, 128)    0           batch_normalization_12[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5000, 128)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 5000, 32)     4096        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 5000, 128)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5000, 32)     13312       conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 5000, 32)     6144        conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 5000, 32)     3072        conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 5000, 128)    0           conv1d_52[0][0]                  \n",
      "                                                                 conv1d_53[0][0]                  \n",
      "                                                                 conv1d_54[0][0]                  \n",
      "                                                                 conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 5000, 128)    512         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 5000, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 5000, 32)     4096        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 5000, 128)    0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 5000, 32)     13312       conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 5000, 32)     6144        conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5000, 32)     3072        conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 5000, 128)    0           conv1d_57[0][0]                  \n",
      "                                                                 conv1d_58[0][0]                  \n",
      "                                                                 conv1d_59[0][0]                  \n",
      "                                                                 conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 5000, 128)    512         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 5000, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 5000, 32)     4096        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 5000, 128)    0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 5000, 32)     13312       conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 5000, 32)     6144        conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 5000, 32)     3072        conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 5000, 128)    0           conv1d_62[0][0]                  \n",
      "                                                                 conv1d_63[0][0]                  \n",
      "                                                                 conv1d_64[0][0]                  \n",
      "                                                                 conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 5000, 128)    16384       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 5000, 128)    512         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 5000, 128)    512         conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 5000, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 5000, 128)    0           batch_normalization_16[0][0]     \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 5000, 128)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 5000, 32)     4096        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 5000, 128)    0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 5000, 32)     13312       conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 5000, 32)     6144        conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 5000, 32)     3072        conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 5000, 32)     4096        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 5000, 128)    0           conv1d_68[0][0]                  \n",
      "                                                                 conv1d_69[0][0]                  \n",
      "                                                                 conv1d_70[0][0]                  \n",
      "                                                                 conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 5000, 128)    512         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 5000, 128)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            3           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 206,437\n",
      "Trainable params: 204,133\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kalfasyan/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.9962553624663709, 1: 1.0037728937728938}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {i : weights[i] for i in range(nb_classes)}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.3552 - acc: 0.8449\n",
      "Epoch 00001: val_acc improved from -inf to 0.81029, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "857/857 [==============================] - 245s 286ms/step - loss: 0.3562 - acc: 0.8447 - val_loss: 0.4652 - val_acc: 0.8103\n",
      "Epoch 2/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.2447 - acc: 0.9033\n",
      "Epoch 00002: val_acc did not improve from 0.81029\n",
      "857/857 [==============================] - 242s 282ms/step - loss: 0.2459 - acc: 0.9031 - val_loss: 3.4187 - val_acc: 0.5633\n",
      "Epoch 3/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9326\n",
      "Epoch 00003: val_acc improved from 0.81029 to 0.92414, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "857/857 [==============================] - 243s 283ms/step - loss: 0.1827 - acc: 0.9324 - val_loss: 0.2011 - val_acc: 0.9241\n",
      "Epoch 4/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9432\n",
      "Epoch 00004: val_acc improved from 0.92414 to 0.93837, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "857/857 [==============================] - 243s 284ms/step - loss: 0.1567 - acc: 0.9431 - val_loss: 0.1692 - val_acc: 0.9384\n",
      "Epoch 5/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9480\n",
      "Epoch 00005: val_acc did not improve from 0.93837\n",
      "857/857 [==============================] - 244s 284ms/step - loss: 0.1418 - acc: 0.9479 - val_loss: 0.4309 - val_acc: 0.8484\n",
      "Epoch 6/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9515\n",
      "Epoch 00006: val_acc did not improve from 0.93837\n",
      "857/857 [==============================] - 244s 284ms/step - loss: 0.1303 - acc: 0.9514 - val_loss: 0.1924 - val_acc: 0.9334\n",
      "Epoch 7/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9560\n",
      "Epoch 00007: val_acc did not improve from 0.93837\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "857/857 [==============================] - 244s 285ms/step - loss: 0.1207 - acc: 0.9559 - val_loss: 0.2124 - val_acc: 0.9308\n",
      "Epoch 8/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9692\n",
      "Epoch 00008: val_acc improved from 0.93837 to 0.96749, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "857/857 [==============================] - 244s 285ms/step - loss: 0.0891 - acc: 0.9690 - val_loss: 0.0898 - val_acc: 0.9675\n",
      "Epoch 9/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9736\n",
      "Epoch 00009: val_acc improved from 0.96749 to 0.96979, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "857/857 [==============================] - 244s 285ms/step - loss: 0.0783 - acc: 0.9734 - val_loss: 0.0909 - val_acc: 0.9698\n",
      "Epoch 10/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9754\n",
      "Epoch 00010: val_acc did not improve from 0.96979\n",
      "857/857 [==============================] - 247s 288ms/step - loss: 0.0728 - acc: 0.9753 - val_loss: 0.0921 - val_acc: 0.9685\n",
      "Epoch 11/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9768\n",
      "Epoch 00011: val_acc did not improve from 0.96979\n",
      "857/857 [==============================] - 243s 284ms/step - loss: 0.0682 - acc: 0.9767 - val_loss: 0.0903 - val_acc: 0.9697\n",
      "Epoch 12/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9790\n",
      "Epoch 00012: val_acc improved from 0.96979 to 0.97066, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "857/857 [==============================] - 244s 284ms/step - loss: 0.0641 - acc: 0.9789 - val_loss: 0.0878 - val_acc: 0.9707\n",
      "Epoch 13/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9804\n",
      "Epoch 00013: val_acc improved from 0.97066 to 0.97099, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "857/857 [==============================] - 245s 286ms/step - loss: 0.0604 - acc: 0.9804 - val_loss: 0.0858 - val_acc: 0.9710\n",
      "Epoch 14/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9816\n",
      "Epoch 00014: val_acc improved from 0.97099 to 0.97230, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "857/857 [==============================] - 245s 286ms/step - loss: 0.0569 - acc: 0.9816 - val_loss: 0.0840 - val_acc: 0.9723\n",
      "Epoch 15/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9829\n",
      "Epoch 00015: val_acc improved from 0.97230 to 0.97263, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "857/857 [==============================] - 246s 287ms/step - loss: 0.0536 - acc: 0.9829 - val_loss: 0.0824 - val_acc: 0.9726\n",
      "Epoch 16/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9844\n",
      "Epoch 00016: val_acc did not improve from 0.97263\n",
      "857/857 [==============================] - 246s 287ms/step - loss: 0.0505 - acc: 0.9844 - val_loss: 0.0821 - val_acc: 0.9726\n",
      "Epoch 17/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9857\n",
      "Epoch 00017: val_acc did not improve from 0.97263\n",
      "857/857 [==============================] - 246s 287ms/step - loss: 0.0474 - acc: 0.9857 - val_loss: 0.0822 - val_acc: 0.9724\n",
      "Epoch 18/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9866\n",
      "Epoch 00018: val_acc did not improve from 0.97263\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "857/857 [==============================] - 246s 287ms/step - loss: 0.0444 - acc: 0.9866 - val_loss: 0.0829 - val_acc: 0.9722\n",
      "Epoch 19/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9889\n",
      "Epoch 00019: val_acc improved from 0.97263 to 0.97318, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "857/857 [==============================] - 246s 287ms/step - loss: 0.0374 - acc: 0.9889 - val_loss: 0.0796 - val_acc: 0.9732\n",
      "Epoch 20/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9899\n",
      "Epoch 00020: val_acc did not improve from 0.97318\n",
      "857/857 [==============================] - 246s 287ms/step - loss: 0.0360 - acc: 0.9899 - val_loss: 0.0797 - val_acc: 0.9730\n",
      "Epoch 21/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9902\n",
      "Epoch 00021: val_acc did not improve from 0.97318\n",
      "857/857 [==============================] - 246s 288ms/step - loss: 0.0352 - acc: 0.9902 - val_loss: 0.0798 - val_acc: 0.9730\n",
      "Epoch 22/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9906\n",
      "Epoch 00022: val_acc did not improve from 0.97318\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "857/857 [==============================] - 247s 288ms/step - loss: 0.0346 - acc: 0.9906 - val_loss: 0.0798 - val_acc: 0.9729\n",
      "Epoch 23/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9908\n",
      "Epoch 00023: val_acc improved from 0.97318 to 0.97373, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_rawflt_dl4tsc_inc_custom.h5\n",
      "857/857 [==============================] - 247s 288ms/step - loss: 0.0335 - acc: 0.9908 - val_loss: 0.0799 - val_acc: 0.9737\n",
      "Epoch 24/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9911\n",
      "Epoch 00024: val_acc did not improve from 0.97373\n",
      "857/857 [==============================] - 247s 288ms/step - loss: 0.0334 - acc: 0.9911 - val_loss: 0.0799 - val_acc: 0.9735\n",
      "Epoch 25/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9911\n",
      "Epoch 00025: val_acc did not improve from 0.97373\n",
      "857/857 [==============================] - 247s 288ms/step - loss: 0.0333 - acc: 0.9911 - val_loss: 0.0799 - val_acc: 0.9733\n",
      "Epoch 26/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9912\n",
      "Epoch 00026: val_acc did not improve from 0.97373\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "857/857 [==============================] - 247s 289ms/step - loss: 0.0332 - acc: 0.9912 - val_loss: 0.0799 - val_acc: 0.9732\n",
      "Epoch 27/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9913\n",
      "Epoch 00027: val_acc did not improve from 0.97373\n",
      "857/857 [==============================] - 247s 288ms/step - loss: 0.0330 - acc: 0.9913 - val_loss: 0.0799 - val_acc: 0.9732\n",
      "Epoch 28/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9913\n",
      "Epoch 00028: val_acc did not improve from 0.97373\n",
      "857/857 [==============================] - 248s 290ms/step - loss: 0.0330 - acc: 0.9913 - val_loss: 0.0799 - val_acc: 0.9732\n",
      "Epoch 29/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9913\n",
      "Epoch 00029: val_acc did not improve from 0.97373\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "857/857 [==============================] - 248s 289ms/step - loss: 0.0330 - acc: 0.9913 - val_loss: 0.0799 - val_acc: 0.9732\n",
      "Epoch 30/100\n",
      "856/857 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9913\n",
      "Epoch 00030: val_acc did not improve from 0.97373\n",
      "857/857 [==============================] - 248s 289ms/step - loss: 0.0330 - acc: 0.9913 - val_loss: 0.0799 - val_acc: 0.9732\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_generator(X_train, y_train, \n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting,\n",
    "                                     preprocessing_train_stats='', binary_labels=True),\n",
    "                    steps_per_epoch = int(math.ceil(float(len(X_train)) / float(traincf.batch_size))),\n",
    "                    epochs = traincf.epochs,\n",
    "                    validation_data = valid_generator(X_val, y_val,\n",
    "                                                        batch_size=traincf.batch_size,\n",
    "                                                        target_names=np.unique(y_test).tolist(),\n",
    "                                                        setting=traincf.setting,\n",
    "                                                         preprocessing_train_stats='', binary_labels=True),\n",
    "                    validation_steps=int(math.ceil(float(len(X_val))/float(traincf.batch_size))),\n",
    "                    callbacks=traincf.callbacks_list,\n",
    "             class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(valid_generator(X_test, y_test,\n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting,\n",
    "                                  preprocessing_train_stats='', binary=True),\n",
    "                              steps=int(math.ceil(float(len(X_test))/float(traincf.batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(pred < 0.5, 0 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8428012916335998"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "balanced_accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'actual')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "cm = cm.astype(np.float) / cm.astype(np.float).sum(axis=0)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='.2g')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0=melanogaster, 1=suzukii, 2=zaprionus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "sub = pd.concat([pd.Series(y_test), pd.Series(X_test)], axis=1)\n",
    "sub['preds'] = y_pred\n",
    "sub.columns = ['labels','fnames','preds']\n",
    "sub['datestr'] = get_wingbeat_dates(sub.fnames)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(f'{TEMP_DATADIR}/df_{model_setting}_{data_setting}_{splitting}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
