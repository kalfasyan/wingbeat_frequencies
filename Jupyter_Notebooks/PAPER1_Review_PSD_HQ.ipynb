{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ae. aegypti', 'Ae. albopictus', 'An. arabiensis', 'An. gambiae', 'C. pipiens', 'C. quinquefasciatus']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from wavhandler import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils_train import train_test_val_split, TrainConfiguration, train_generator\n",
    "from utils_train import valid_generator,mosquito_data_split, train_model_ml\n",
    "import deepdish as dd\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, log_loss\n",
    "from sklearn.model_selection import cross_val_score\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "splitting = \"random\"\n",
    "data_setting = \"psdHQ\"\n",
    "model_setting = \"xgboost\"\n",
    "\n",
    "assert splitting in ['random','randomcv','custom'], \"Wrong splitting method given.\"\n",
    "assert data_setting in ['raw','psd_dB','psdHQ'], \"Wrong data settting given.\"\n",
    "assert model_setting in ['knn','randomforest','xgboost']\n",
    "\n",
    "data = Dataset('Wingbeats')\n",
    "print(data.target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING DATA random\n",
      "Species: Ae. aegypti.\n",
      "Read 85553 filenames in 2.86 seconds.\n",
      "Species: Ae. albopictus.\n",
      "Read 20231 filenames in 2.72 seconds.\n",
      "Species: An. arabiensis.\n",
      "Read 19297 filenames in 2.95 seconds.\n",
      "Species: An. gambiae.\n",
      "Read 49471 filenames in 2.70 seconds.\n",
      "Species: C. pipiens.\n",
      "Read 30415 filenames in 2.82 seconds.\n",
      "Species: C. quinquefasciatus.\n",
      "Read 74599 filenames in 3.14 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(f'SPLITTING DATA {splitting}')\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = mosquito_data_split(splitting=splitting, dataset=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.28 s, sys: 245 ms, total: 2.52 s\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "x_test = make_df_parallel(names=X_test, setting=data_setting).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if \"RANDOM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "if splitting in ['random', 'randomcv']:\n",
    "    X_train.extend(X_val)\n",
    "    y_train.extend(y_val)\n",
    "    x_train = make_df_parallel(names=X_train, setting=data_setting).values\n",
    "    x_val = make_df_parallel(names=X_val, setting=data_setting).values\n",
    "\n",
    "    model, res = train_model_ml(dataset=data,\n",
    "                            model_setting=model_setting,\n",
    "                            splitting=splitting, \n",
    "                            data_setting=data_setting,\n",
    "                            x_train=x_train, \n",
    "                            y_train=y_train, \n",
    "                            x_val=x_val, \n",
    "                            y_val=y_val, \n",
    "                            x_test=x_test, \n",
    "                            y_test=y_test,\n",
    "                            flag='ML')\n",
    "    results[splitting] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if \"CUSTOM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if splitting == 'custom':\n",
    "    train_scores, val_scores, cms, b_accs, logloss, clf_reports, y_preds, y_pred_probas = [],[],[],[],[],[],[],[]\n",
    "    for i in range(5):\n",
    "        x_train_fold = make_df_parallel(names=X_train[i], setting=data_setting).values\n",
    "        x_val_fold = make_df_parallel(names=X_val[i], setting=data_setting).values\n",
    "        estimator = train_model_ml(dataset=data,\n",
    "                                    model_setting=model_setting,\n",
    "                                    splitting=splitting, \n",
    "                                    data_setting=data_setting,\n",
    "                                    x_train=x_train_fold, \n",
    "                                    y_train=y_train[i], \n",
    "                                    x_val=x_val_fold, \n",
    "                                    y_val=y_val[i], \n",
    "                                    x_test=x_test, \n",
    "                                    y_test=y_test,\n",
    "                                    flag=f'split_{i}')\n",
    "\n",
    "        y_preds.append( estimator.predict(x_test) )\n",
    "        y_pred_probas.append( estimator.predict_proba(x_test) )\n",
    "        train_scores.append( balanced_accuracy_score(y_train[i], estimator.predict(x_train_fold)) )\n",
    "        val_scores.append( balanced_accuracy_score(y_val[i], estimator.predict(x_val_fold)) )\n",
    "        cms.append(confusion_matrix(y_test, y_preds[i]))\n",
    "        b_accs.append(balanced_accuracy_score(y_test, y_preds[i]))\n",
    "        logloss.append(log_loss(y_test, y_pred_probas[i]))\n",
    "        clf_reports.append(classification_report(y_test, y_preds[i], target_names=data.target_classes))\n",
    "\n",
    "    mean_train_score = np.mean(train_scores)\n",
    "    mean_val_score = np.mean(val_scores)\n",
    "    mean_test_score = np.mean(b_accs)\n",
    "    mean_test_logloss = np.mean(logloss)\n",
    "    \n",
    "    results['y_preds'] = y_preds\n",
    "    results['y_pred_probas'] = y_pred_probas\n",
    "    results['y_test'] = y_test\n",
    "    results['cms'] = cms\n",
    "    results['b_accs'] = b_accs\n",
    "    results['logloss'] = logloss\n",
    "    results['clf_reports'] = clf_reports\n",
    "    results['train_score'] = mean_train_score\n",
    "    results['val_score'] = mean_val_score\n",
    "    results['balanced_acc_test'] = mean_test_score\n",
    "    results['logloss_test'] = mean_test_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.io.save(f'{TEMP_DATADIR}/{splitting}_{data_setting}_{model_setting}_results.h5', \n",
    "            {f'results': results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
