{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from wavhandler import *\n",
    "from configs import DatasetConfiguration\n",
    "from utils_train import *\n",
    "from configs import *\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, classification_report, make_scorer, log_loss\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "import seaborn as sb\n",
    "import deepdish as dd\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "splitting = 'custom'\n",
    "data_setting = 'rawflt'#'stftflt'\n",
    "model_setting = 'dl4tsc_inc'#'DenseNet121'\n",
    "\n",
    "clean = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{TEMP_DATADIR}/df_train_{data_setting}_{model_setting}_{splitting}.csv\", index_col=False)\n",
    "X_train = train.x.tolist()\n",
    "y_train = train.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(f\"{TEMP_DATADIR}/df_val_{data_setting}_{model_setting}_{splitting}.csv\", index_col=False)\n",
    "X_val = val.x.tolist()\n",
    "y_val = val.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{TEMP_DATADIR}/df_test_{data_setting}_{model_setting}_{splitting}.csv\", index_col=False)\n",
    "X_test = test.x.tolist()\n",
    "y_test = test.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "1    12377\n",
      "0     3658\n",
      "dtype: int64\n",
      "\n",
      "val: \n",
      "1    4124\n",
      "0    1221\n",
      "dtype: int64\n",
      "\n",
      "test: \n",
      "1    11457\n",
      "0     1157\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: \\n{pd.Series(y_train).value_counts()}\\n\")\n",
    "print(f\"val: \\n{pd.Series(y_val).value_counts()}\\n\")\n",
    "print(f\"test: \\n{pd.Series(y_test).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MosquitoNet & Building top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ae. aegypti', 'Ae. albopictus', 'An. arabiensis', 'An. gambiae', 'C. pipiens', 'C. quinquefasciatus']\n",
      "############ INPUT SHAPE:(5000, 1)\n",
      "/home/kalfasyan/projects/wingbeat_frequencies/temp_data/\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/home/kalfasyan/projects/wingbeat_frequencies/temp_data/MosquitoNET_rawflt_dl4tsc_inc_random_.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-701dba3b7209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraincf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    248\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    249\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   def compile(self,\n",
      "\u001b[0;32m~/anaconda3/envs/wbtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1257\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   1258\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wbtf/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wbtf/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/home/kalfasyan/projects/wingbeat_frequencies/temp_data/MosquitoNET_rawflt_dl4tsc_inc_random_.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "data = Dataset('Wingbeats')\n",
    "print(data.target_classes)\n",
    "\n",
    "dataset = data\n",
    "splitting='random'\n",
    "flag = ''\n",
    "traincf = TrainConfiguration(nb_classes=6, setting=data_setting, model_name=f'MosquitoNET_{data_setting}_{model_setting}_{splitting}_{flag}')\n",
    "using_conv2d = False\n",
    "base_model = ModelConfiguration(model_setting=model_setting, data_setting=data_setting, nb_classes=6).config\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "base_model.load_weights(traincf.top_weights_path)\n",
    "base_model.trainable = False\n",
    "\n",
    "if data_setting == 'rawflt':\n",
    "    model = Sequential()\n",
    "    for layer in base_model.layers[:-1]: # go through until last layer\n",
    "        model.add(layer)\n",
    "    #     print(layer.trainable)\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "elif data_setting == 'stftflt':\n",
    "    base_output = base_model.layers[-2].output\n",
    "    new_output = Dense(3, activation=\"softmax\")(base_output)\n",
    "    model = Model(inputs=base_model.inputs, outputs=new_output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# # inputs = Input(shape=)\n",
    "# inputs = Input(shape=base_model.input.shape[1:])\n",
    "# x = base_model(inputs, training=False)\n",
    "# # x =  GlobalAveragePooling2D()(x)\n",
    "# # x = Dropout(0.2)(x)\n",
    "# outputs = Dense(3)(x)\n",
    "# model = Model(inputs, outputs)\n",
    "# model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training top layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8670\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.90183, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 112s 186ms/step - loss: 0.3494 - accuracy: 0.8670 - val_loss: 0.2821 - val_accuracy: 0.9018 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "603/605 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.9019\n",
      "Epoch 00002: val_accuracy improved from 0.90183 to 0.91284, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 51ms/step - loss: 0.2719 - accuracy: 0.9020 - val_loss: 0.2527 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "604/605 [============================>.] - ETA: 0s - loss: 0.2510 - accuracy: 0.9110\n",
      "Epoch 00003: val_accuracy improved from 0.91284 to 0.92075, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 32s 52ms/step - loss: 0.2509 - accuracy: 0.9110 - val_loss: 0.2361 - val_accuracy: 0.9208 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "604/605 [============================>.] - ETA: 0s - loss: 0.2376 - accuracy: 0.9172\n",
      "Epoch 00004: val_accuracy improved from 0.92075 to 0.92556, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 52ms/step - loss: 0.2375 - accuracy: 0.9172 - val_loss: 0.2247 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "604/605 [============================>.] - ETA: 0s - loss: 0.2276 - accuracy: 0.9218\n",
      "Epoch 00005: val_accuracy improved from 0.92556 to 0.92897, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 32s 53ms/step - loss: 0.2276 - accuracy: 0.9218 - val_loss: 0.2162 - val_accuracy: 0.9290 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.2198 - accuracy: 0.9245\n",
      "Epoch 00006: val_accuracy improved from 0.92897 to 0.93114, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 52ms/step - loss: 0.2198 - accuracy: 0.9245 - val_loss: 0.2096 - val_accuracy: 0.9311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "604/605 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9276\n",
      "Epoch 00007: val_accuracy improved from 0.93114 to 0.93254, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 32s 54ms/step - loss: 0.2135 - accuracy: 0.9276 - val_loss: 0.2043 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.9296\n",
      "Epoch 00008: val_accuracy improved from 0.93254 to 0.93455, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 32s 54ms/step - loss: 0.2082 - accuracy: 0.9296 - val_loss: 0.2000 - val_accuracy: 0.9346 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.9311\n",
      "Epoch 00009: val_accuracy did not improve from 0.93455\n",
      "605/605 [==============================] - 30s 50ms/step - loss: 0.2038 - accuracy: 0.9311 - val_loss: 0.1963 - val_accuracy: 0.9346 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9315\n",
      "Epoch 00010: val_accuracy improved from 0.93455 to 0.93579, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 51ms/step - loss: 0.1999 - accuracy: 0.9315 - val_loss: 0.1932 - val_accuracy: 0.9358 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1966 - accuracy: 0.9327\n",
      "Epoch 00011: val_accuracy improved from 0.93579 to 0.93626, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 51ms/step - loss: 0.1966 - accuracy: 0.9327 - val_loss: 0.1905 - val_accuracy: 0.9363 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.9332\n",
      "Epoch 00012: val_accuracy improved from 0.93626 to 0.93688, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 51ms/step - loss: 0.1936 - accuracy: 0.9332 - val_loss: 0.1882 - val_accuracy: 0.9369 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.9341\n",
      "Epoch 00013: val_accuracy improved from 0.93688 to 0.93734, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 52ms/step - loss: 0.1910 - accuracy: 0.9341 - val_loss: 0.1862 - val_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9348\n",
      "Epoch 00014: val_accuracy improved from 0.93734 to 0.93812, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 51ms/step - loss: 0.1886 - accuracy: 0.9348 - val_loss: 0.1843 - val_accuracy: 0.9381 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.9358\n",
      "Epoch 00015: val_accuracy improved from 0.93812 to 0.93859, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 51ms/step - loss: 0.1865 - accuracy: 0.9358 - val_loss: 0.1827 - val_accuracy: 0.9386 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.9364\n",
      "Epoch 00016: val_accuracy did not improve from 0.93859\n",
      "605/605 [==============================] - 31s 51ms/step - loss: 0.1845 - accuracy: 0.9364 - val_loss: 0.1813 - val_accuracy: 0.9384 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9365\n",
      "Epoch 00017: val_accuracy improved from 0.93859 to 0.93998, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 52ms/step - loss: 0.1827 - accuracy: 0.9365 - val_loss: 0.1800 - val_accuracy: 0.9400 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1811 - accuracy: 0.9369\n",
      "Epoch 00018: val_accuracy improved from 0.93998 to 0.94122, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 52ms/step - loss: 0.1811 - accuracy: 0.9369 - val_loss: 0.1788 - val_accuracy: 0.9412 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.9370\n",
      "Epoch 00019: val_accuracy improved from 0.94122 to 0.94153, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 31s 52ms/step - loss: 0.1796 - accuracy: 0.9370 - val_loss: 0.1777 - val_accuracy: 0.9415 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9373\n",
      "Epoch 00020: val_accuracy did not improve from 0.94153\n",
      "605/605 [==============================] - 31s 50ms/step - loss: 0.1781 - accuracy: 0.9373 - val_loss: 0.1767 - val_accuracy: 0.9415 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "traincf = TrainConfiguration(nb_classes=3, setting=data_setting, model_name=f\"Flies_TL_{data_setting}_{model_setting}_{splitting}\", monitor='val_accuracy', epochs=20)\n",
    "\n",
    "h = model.fit(train_generator(X_train, y_train, \n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting,\n",
    "                                     preprocessing_train_stats=''),\n",
    "                    steps_per_epoch = int(math.ceil(float(len(X_train)) / float(traincf.batch_size))),\n",
    "                    epochs = traincf.epochs,\n",
    "                    validation_data = valid_generator(X_val, y_val,\n",
    "                                                        batch_size=traincf.batch_size,\n",
    "                                                        target_names=np.unique(y_test).tolist(),\n",
    "                                                        setting=traincf.setting,\n",
    "                                                         preprocessing_train_stats=''),\n",
    "                    validation_steps=int(math.ceil(float(len(X_val))/float(traincf.batch_size))),\n",
    "              callbacks=[traincf.callbacks_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 129, 120, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 135, 126, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 65, 60, 64)   3136        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 65, 60, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 65, 60, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 67, 62, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 33, 30, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 33, 30, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 33, 30, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 33, 30, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 33, 30, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 33, 30, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 33, 30, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 33, 30, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 33, 30, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 33, 30, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 33, 30, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 33, 30, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 33, 30, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 33, 30, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 33, 30, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 33, 30, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 33, 30, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 33, 30, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 33, 30, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 33, 30, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 33, 30, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 33, 30, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 33, 30, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 33, 30, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 33, 30, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 33, 30, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 33, 30, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 33, 30, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 33, 30, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 33, 30, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 33, 30, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 33, 30, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 33, 30, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 33, 30, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 33, 30, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 33, 30, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 33, 30, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 33, 30, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 33, 30, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 33, 30, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 33, 30, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 33, 30, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 33, 30, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 33, 30, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 33, 30, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 33, 30, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 16, 15, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 15, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 16, 15, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 15, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 15, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 15, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 15, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 16, 15, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 16, 15, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 16, 15, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 15, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 15, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 15, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 15, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 16, 15, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 16, 15, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 16, 15, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 15, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 15, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 15, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 15, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 16, 15, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 16, 15, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 16, 15, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 15, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 15, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 15, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 15, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 16, 15, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 16, 15, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 16, 15, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 16, 15, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 16, 15, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 16, 15, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 16, 15, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 16, 15, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 16, 15, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 16, 15, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 16, 15, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 16, 15, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 16, 15, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 16, 15, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 16, 15, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 16, 15, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 16, 15, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 16, 15, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 16, 15, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 16, 15, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 16, 15, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 16, 15, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 16, 15, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 16, 15, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 16, 15, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 16, 15, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 16, 15, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 16, 15, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 16, 15, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 16, 15, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 16, 15, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 16, 15, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 16, 15, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 16, 15, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 16, 15, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 16, 15, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 16, 15, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 16, 15, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 16, 15, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 16, 15, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 16, 15, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 16, 15, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 16, 15, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 16, 15, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 16, 15, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 16, 15, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 16, 15, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 16, 15, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 16, 15, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 16, 15, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 16, 15, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 16, 15, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 16, 15, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 16, 15, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 16, 15, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 16, 15, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 16, 15, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 16, 15, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 16, 15, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 16, 15, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 8, 7, 256)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 7, 256)    1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 8, 7, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 7, 128)    32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 7, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 7, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 7, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 8, 7, 288)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 8, 7, 288)    1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 8, 7, 288)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 7, 128)    36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 7, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 7, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 7, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 8, 7, 320)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 8, 7, 320)    1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 8, 7, 320)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 7, 128)    40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 7, 128)    512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 7, 128)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 7, 32)     36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 8, 7, 352)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 8, 7, 352)    1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 8, 7, 352)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 7, 128)    45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 7, 128)    512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 7, 128)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 7, 32)     36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 8, 7, 384)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 8, 7, 384)    1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 8, 7, 384)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 7, 128)    49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 7, 128)    512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 7, 128)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 7, 32)     36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 8, 7, 416)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 8, 7, 416)    1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 8, 7, 416)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 7, 128)    53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 7, 128)    512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 7, 128)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 7, 32)     36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 8, 7, 448)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 8, 7, 448)    1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 8, 7, 448)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 8, 7, 128)    57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 8, 7, 128)    512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 8, 7, 128)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 8, 7, 32)     36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 8, 7, 480)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 8, 7, 480)    1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 8, 7, 480)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 8, 7, 128)    61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 8, 7, 128)    512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 8, 7, 128)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 8, 7, 32)     36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 8, 7, 512)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 8, 7, 512)    2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 8, 7, 512)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 8, 7, 128)    65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 8, 7, 128)    512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 8, 7, 128)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 8, 7, 32)     36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 8, 7, 544)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 8, 7, 544)    2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 8, 7, 544)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 8, 7, 128)    69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 8, 7, 576)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 8, 7, 576)    2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 8, 7, 576)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 8, 7, 128)    73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 8, 7, 608)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 8, 7, 608)    2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 8, 7, 608)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 8, 7, 128)    77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 8, 7, 640)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 8, 7, 640)    2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 8, 7, 640)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 8, 7, 128)    81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 8, 7, 672)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 8, 7, 672)    2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 8, 7, 672)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 8, 7, 128)    86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 8, 7, 704)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 8, 7, 704)    2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 8, 7, 704)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 8, 7, 128)    90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 8, 7, 736)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 8, 7, 736)    2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 8, 7, 736)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 8, 7, 128)    94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 8, 7, 768)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 8, 7, 768)    3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 8, 7, 768)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 8, 7, 128)    98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 8, 7, 800)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 8, 7, 800)    3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 8, 7, 800)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 8, 7, 128)    102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 8, 7, 832)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 8, 7, 832)    3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 8, 7, 832)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 8, 7, 128)    106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 8, 7, 864)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 8, 7, 864)    3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 8, 7, 864)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 8, 7, 128)    110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 8, 7, 896)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 8, 7, 896)    3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 8, 7, 896)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 8, 7, 128)    114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 8, 7, 928)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 8, 7, 928)    3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 8, 7, 928)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 8, 7, 128)    118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 8, 7, 960)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 8, 7, 960)    3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 8, 7, 960)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 8, 7, 128)    122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 8, 7, 992)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 8, 7, 992)    3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 8, 7, 992)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 8, 7, 128)    126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 8, 7, 128)    512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 8, 7, 128)    0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 8, 7, 32)     36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 8, 7, 1024)   0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 8, 7, 1024)   4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 8, 7, 1024)   0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 8, 7, 512)    524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 4, 3, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 3, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 4, 3, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 3, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 3, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 3, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 3, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 4, 3, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 4, 3, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 4, 3, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 3, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 3, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 3, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 3, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 4, 3, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 4, 3, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 4, 3, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 3, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 3, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 3, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 3, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 4, 3, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 4, 3, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 4, 3, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 4, 3, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 4, 3, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 4, 3, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 4, 3, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 4, 3, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 4, 3, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 4, 3, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 4, 3, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 4, 3, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 4, 3, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 4, 3, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 4, 3, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 4, 3, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 4, 3, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 4, 3, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 4, 3, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 4, 3, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 4, 3, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 4, 3, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 4, 3, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 4, 3, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 4, 3, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 4, 3, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 4, 3, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 4, 3, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 4, 3, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 4, 3, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 4, 3, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 4, 3, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 4, 3, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 4, 3, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 4, 3, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 4, 3, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 4, 3, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 4, 3, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 4, 3, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 4, 3, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 4, 3, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 4, 3, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 4, 3, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 4, 3, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 4, 3, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 4, 3, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 4, 3, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 4, 3, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 4, 3, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 4, 3, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 4, 3, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 4, 3, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 4, 3, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 4, 3, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 4, 3, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 4, 3, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 4, 3, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 4, 3, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 4, 3, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 4, 3, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 4, 3, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 4, 3, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 4, 3, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 4, 3, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 4, 3, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 4, 3, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 4, 3, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 4, 3, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 4, 3, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 4, 3, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 4, 3, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 4, 3, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 4, 3, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 4, 3, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 4, 3, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 4, 3, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 4, 3, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 4, 3, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 4, 3, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 4, 3, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 4, 3, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 4, 3, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 4, 3, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 4, 3, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 4, 3, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 4, 3, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 4, 3, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 4, 3, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 4, 3, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 4, 3, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 4, 3, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 4, 3, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, 3, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 4, 3, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            3075        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,034,307\n",
      "Trainable params: 6,950,659\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-5),  # Low learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "traincf = TrainConfiguration(nb_classes=3, setting=data_setting, model_name=f\"Flies_TL_{data_setting}_{model_setting}_{splitting}\", monitor='val_accuracy', epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 1.0316 - accuracy: 0.7941\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89485, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 206s 341ms/step - loss: 1.0316 - accuracy: 0.7941 - val_loss: 0.4029 - val_accuracy: 0.8949 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.8917\n",
      "Epoch 00002: val_accuracy improved from 0.89485 to 0.91424, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.3682 - accuracy: 0.8917 - val_loss: 0.2842 - val_accuracy: 0.9142 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.9124\n",
      "Epoch 00003: val_accuracy improved from 0.91424 to 0.93006, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.2733 - accuracy: 0.9124 - val_loss: 0.2306 - val_accuracy: 0.9301 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9251\n",
      "Epoch 00004: val_accuracy improved from 0.93006 to 0.93828, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.2261 - accuracy: 0.9251 - val_loss: 0.1969 - val_accuracy: 0.9383 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1937 - accuracy: 0.9343\n",
      "Epoch 00005: val_accuracy improved from 0.93828 to 0.94681, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 103ms/step - loss: 0.1937 - accuracy: 0.9343 - val_loss: 0.1730 - val_accuracy: 0.9468 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9410\n",
      "Epoch 00006: val_accuracy improved from 0.94681 to 0.95239, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.1697 - accuracy: 0.9410 - val_loss: 0.1567 - val_accuracy: 0.9524 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.9461\n",
      "Epoch 00007: val_accuracy improved from 0.95239 to 0.95549, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 103ms/step - loss: 0.1523 - accuracy: 0.9461 - val_loss: 0.1450 - val_accuracy: 0.9555 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.9514\n",
      "Epoch 00008: val_accuracy improved from 0.95549 to 0.95689, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.1388 - accuracy: 0.9514 - val_loss: 0.1369 - val_accuracy: 0.9569 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9553\n",
      "Epoch 00009: val_accuracy improved from 0.95689 to 0.95797, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.1278 - accuracy: 0.9553 - val_loss: 0.1309 - val_accuracy: 0.9580 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9589\n",
      "Epoch 00010: val_accuracy improved from 0.95797 to 0.95983, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.1184 - accuracy: 0.9589 - val_loss: 0.1268 - val_accuracy: 0.9598 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9608\n",
      "Epoch 00011: val_accuracy improved from 0.95983 to 0.96061, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.1104 - accuracy: 0.9608 - val_loss: 0.1234 - val_accuracy: 0.9606 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9638\n",
      "Epoch 00012: val_accuracy improved from 0.96061 to 0.96076, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.1033 - accuracy: 0.9638 - val_loss: 0.1201 - val_accuracy: 0.9608 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9661\n",
      "Epoch 00013: val_accuracy improved from 0.96076 to 0.96154, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.0968 - accuracy: 0.9661 - val_loss: 0.1179 - val_accuracy: 0.9615 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9686\n",
      "Epoch 00014: val_accuracy improved from 0.96154 to 0.96247, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.0909 - accuracy: 0.9686 - val_loss: 0.1157 - val_accuracy: 0.9625 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9702\n",
      "Epoch 00015: val_accuracy improved from 0.96247 to 0.96309, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 103ms/step - loss: 0.0854 - accuracy: 0.9702 - val_loss: 0.1145 - val_accuracy: 0.9631 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9727\n",
      "Epoch 00016: val_accuracy improved from 0.96309 to 0.96340, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 103ms/step - loss: 0.0803 - accuracy: 0.9727 - val_loss: 0.1134 - val_accuracy: 0.9634 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9748\n",
      "Epoch 00017: val_accuracy did not improve from 0.96340\n",
      "605/605 [==============================] - 61s 100ms/step - loss: 0.0754 - accuracy: 0.9748 - val_loss: 0.1125 - val_accuracy: 0.9634 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9770\n",
      "Epoch 00018: val_accuracy improved from 0.96340 to 0.96371, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 103ms/step - loss: 0.0709 - accuracy: 0.9770 - val_loss: 0.1116 - val_accuracy: 0.9637 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9785\n",
      "Epoch 00019: val_accuracy improved from 0.96371 to 0.96433, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 103ms/step - loss: 0.0665 - accuracy: 0.9785 - val_loss: 0.1112 - val_accuracy: 0.9643 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9805\n",
      "Epoch 00020: val_accuracy improved from 0.96433 to 0.96449, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.0624 - accuracy: 0.9805 - val_loss: 0.1108 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9816\n",
      "Epoch 00021: val_accuracy did not improve from 0.96449\n",
      "605/605 [==============================] - 61s 100ms/step - loss: 0.0583 - accuracy: 0.9816 - val_loss: 0.1105 - val_accuracy: 0.9643 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9831\n",
      "Epoch 00022: val_accuracy improved from 0.96449 to 0.96480, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.0544 - accuracy: 0.9831 - val_loss: 0.1104 - val_accuracy: 0.9648 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9847\n",
      "Epoch 00023: val_accuracy improved from 0.96480 to 0.96526, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.0507 - accuracy: 0.9847 - val_loss: 0.1106 - val_accuracy: 0.9653 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9865\n",
      "Epoch 00024: val_accuracy did not improve from 0.96526\n",
      "605/605 [==============================] - 60s 100ms/step - loss: 0.0471 - accuracy: 0.9865 - val_loss: 0.1110 - val_accuracy: 0.9651 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9879\n",
      "Epoch 00025: val_accuracy improved from 0.96526 to 0.96635, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 102ms/step - loss: 0.0437 - accuracy: 0.9879 - val_loss: 0.1113 - val_accuracy: 0.9663 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9895\n",
      "Epoch 00026: val_accuracy improved from 0.96635 to 0.96681, saving model to /home/kalfasyan/projects/wingbeat_frequencies/temp_data/Flies_TL_stftflt_DenseNet121_random.h5\n",
      "605/605 [==============================] - 62s 103ms/step - loss: 0.0404 - accuracy: 0.9895 - val_loss: 0.1116 - val_accuracy: 0.9668 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9905\n",
      "Epoch 00027: val_accuracy did not improve from 0.96681\n",
      "605/605 [==============================] - 61s 100ms/step - loss: 0.0372 - accuracy: 0.9905 - val_loss: 0.1117 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9919\n",
      "Epoch 00028: val_accuracy did not improve from 0.96681\n",
      "605/605 [==============================] - 61s 100ms/step - loss: 0.0342 - accuracy: 0.9919 - val_loss: 0.1120 - val_accuracy: 0.9668 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9930\n",
      "Epoch 00029: val_accuracy did not improve from 0.96681\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "605/605 [==============================] - 61s 100ms/step - loss: 0.0313 - accuracy: 0.9930 - val_loss: 0.1133 - val_accuracy: 0.9668 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9944\n",
      "Epoch 00030: val_accuracy did not improve from 0.96681\n",
      "605/605 [==============================] - 61s 100ms/step - loss: 0.0275 - accuracy: 0.9944 - val_loss: 0.1097 - val_accuracy: 0.9632 - lr: 1.0000e-06\n",
      "Epoch 31/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9947\n",
      "Epoch 00031: val_accuracy did not improve from 0.96681\n",
      "605/605 [==============================] - 60s 100ms/step - loss: 0.0267 - accuracy: 0.9947 - val_loss: 0.1107 - val_accuracy: 0.9632 - lr: 1.0000e-06\n",
      "Epoch 32/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9948\n",
      "Epoch 00032: val_accuracy did not improve from 0.96681\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "605/605 [==============================] - 61s 100ms/step - loss: 0.0263 - accuracy: 0.9948 - val_loss: 0.1110 - val_accuracy: 0.9625 - lr: 1.0000e-06\n",
      "Epoch 33/100\n",
      "605/605 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9947\n",
      "Epoch 00033: val_accuracy did not improve from 0.96681\n",
      "605/605 [==============================] - 61s 100ms/step - loss: 0.0258 - accuracy: 0.9947 - val_loss: 0.1081 - val_accuracy: 0.9654 - lr: 1.0000e-07\n",
      "Epoch 00033: early stopping\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_generator(X_train, y_train, \n",
    "                              batch_size=traincf.batch_size,\n",
    "                              target_names=np.unique(y_test).tolist(),\n",
    "                              setting=traincf.setting,\n",
    "                              preprocessing_train_stats=''),\n",
    "              steps_per_epoch = int(math.ceil(float(len(X_train)) / float(traincf.batch_size))),\n",
    "              epochs = traincf.epochs,\n",
    "              validation_data = valid_generator(X_val, y_val,\n",
    "                                                batch_size=traincf.batch_size,\n",
    "                                                target_names=np.unique(y_test).tolist(),\n",
    "                                                setting=traincf.setting,\n",
    "                                                preprocessing_train_stats=''),\n",
    "              validation_steps=int(math.ceil(float(len(X_val))/float(traincf.batch_size))),\n",
    "              callbacks=[traincf.callbacks_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-f14ba622748d>:6: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_generator(valid_generator(X_test, y_test,\n",
    "                                    batch_size=traincf.batch_size,\n",
    "                                    target_names=np.unique(y_test).tolist(),\n",
    "                                    setting=traincf.setting,\n",
    "                                  preprocessing_train_stats=''),\n",
    "                              steps=int(math.ceil(float(len(X_test))/float(traincf.batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8811349364759824"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "balanced_accuracy_score(y_true=y_test, y_pred=np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE PLOT_CONFUSION_MATRIX FROM SKLEARN.METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc4681beb50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=np.argmax(pred, axis=1))\n",
    "cm = cm.astype(np.float) / cm.astype(np.float).sum(axis=0)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='.3g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result of rawflt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7930029f50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=np.argmax(pred, axis=1))\n",
    "cm = cm.astype(np.float) / cm.astype(np.float).sum(axis=1)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='.3g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if misclassifications are the same for normal training vs transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
