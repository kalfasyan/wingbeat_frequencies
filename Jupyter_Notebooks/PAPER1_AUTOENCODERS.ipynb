{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from wavhandler import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils_train import train_test_val_split, TrainConfiguration, train_generator, valid_generator,mosquito_data_split, train_model_dl\n",
    "from utils_train import n_cpus\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ae. aegypti', 'Ae. albopictus', 'An. arabiensis', 'An. gambiae', 'C. pipiens', 'C. quinquefasciatus']\n",
      "SPLITTING DATA randomcv\n",
      "Species: Ae. aegypti.\n",
      "Read 85553 filenames in 2.38 seconds.\n",
      "['20170209', '20170208', '20170210', '20170206', '20170213', '20170211', '20170207', '20161213', '20170212', '20161212']\n",
      "82989 train filenames, 2564 test filenames\n",
      "Species: Ae. albopictus.\n",
      "Read 20231 filenames in 2.37 seconds.\n",
      "['20170301', '20170228', '20170227', '20170103', '20170102']\n",
      "17440 train filenames, 2791 test filenames\n",
      "Species: An. arabiensis.\n",
      "Read 19297 filenames in 2.36 seconds.\n",
      "['20170313', '20170202', '20170315', '20170314', '20170318', '20170204', '20170201', '20170131', '20170203', '20170317', '20170320', '20170319', '20170316', '20170205', '20170206', '20170130']\n",
      "12897 train filenames, 2831 test filenames\n",
      "Species: An. gambiae.\n",
      "Read 49471 filenames in 2.27 seconds.\n",
      "['20170110', '20170109', '20170116', '20170119', '20170120', '20170117', '20170121', '20170118', '20170122', '20170123']\n",
      "45471 train filenames, 4000 test filenames\n",
      "Species: C. quinquefasciatus.\n",
      "Read 74599 filenames in 2.42 seconds.\n",
      "['20161220', '20161219', '20161221']\n",
      "41552 train filenames, 33047 test filenames\n",
      "Species: C. pipiens.\n",
      "Read 30415 filenames in 2.33 seconds.\n",
      "['20161206', '20161205', '20170215', '20170216', '20170220', '20170217', '20170214', '20170213', '20170219', '20170218']\n",
      "28353 train filenames, 2062 test filenames\n"
     ]
    }
   ],
   "source": [
    "splitting = 'randomcv'\n",
    "data_setting = 'raw'\n",
    "model_setting = 'conv1d'\n",
    "\n",
    "assert splitting in ['random','randomcv','custom'], \"Wrong splitting method given.\"\n",
    "assert data_setting in ['raw','stft','psd_dB'], \"Wrong data settting given.\"\n",
    "assert model_setting in ['wavenet','lstm','gru','conv1d','conv1d_psd',\n",
    "                        'DenseNet121','DenseNet169','DenseNet201',\n",
    "                        'InceptionResNetV2','VGG16','VGG19'], \"Wrong model setting given\"\n",
    "\n",
    "data = Dataset('Wingbeats')\n",
    "print(data.target_classes)\n",
    "\n",
    "print(f'SPLITTING DATA {splitting}')\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = mosquito_data_split(splitting=splitting, dataset=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_train import ModelConfiguration, TrainConfiguration\n",
    "\n",
    "traincf = TrainConfiguration(dataset=data, \n",
    "                             setting=data_setting,\n",
    "                             batch_size=64,\n",
    "                             model_name=f'{splitting}_{data_setting}_{model_setting}_ss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 2\n",
    "input_img = Input(batch_shape=(None,5000,1))\n",
    "# encoder = Conv1D(256,3, activation='relu', padding='same')(input_img)\n",
    "# encoder = Conv1D(256,3, activation='relu', padding='same')(encoder)\n",
    "# encoder = MaxPooling1D(2)(encoder)\n",
    "# encoder = Conv1D(128,3, activation='relu', padding='same')(input_img)\n",
    "# encoder = Conv1D(128,3, activation='relu', padding='same')(encoder)\n",
    "# encoder = MaxPooling1D(2)(encoder)\n",
    "encoder = Conv1D(64,3, activation='relu', padding='same')(input_img)\n",
    "encoder = Conv1D(64,3, activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling1D(2)(encoder)\n",
    "encoder = Conv1D(32,3, activation='relu', padding='same')(encoder)\n",
    "encoder = Conv1D(32,3, activation='relu', padding='same')(encoder)\n",
    "# encoder = BatchNormalization()(encoder)\n",
    "encoder = MaxPooling1D(2)(encoder)\n",
    "encoder = Conv1D(16,3, activation='relu', padding='same')(encoder)\n",
    "encoder = Conv1D(16,3, activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling1D(2)(encoder)\n",
    "\n",
    "encoder = Dense(encoding_dim, activation='relu')(encoder)\n",
    "\n",
    "decoder = Conv1D(16, 3, activation='relu', padding='same')(encoder)\n",
    "decoder = Conv1D(16, 3, activation='relu', padding='same')(decoder)\n",
    "decoder =  UpSampling1D(2)(decoder)\n",
    "decoder = Conv1D(32, 3, activation='relu', padding='same')(decoder)\n",
    "decoder = Conv1D(32, 3, activation='relu', padding='same')(decoder)\n",
    "decoder =  UpSampling1D(2)(decoder)\n",
    "# decoder = BatchNormalization()(decoder)\n",
    "decoder = Conv1D(64, 3, activation='relu', padding='same')(decoder)\n",
    "decoder = Conv1D(64, 3, activation='relu', padding='same')(decoder)\n",
    "decoder =  UpSampling1D(2)(decoder)\n",
    "# decoder = Conv1D(128, 3, activation='relu', padding='same')(decoder)\n",
    "# decoder = Conv1D(128, 3, activation='relu', padding='same')(decoder)\n",
    "# decoder =  UpSampling1D(2)(decoder)\n",
    "# decoder = Conv1D(256, 3, activation='relu', padding='same')(decoder)\n",
    "# decoder = Conv1D(256, 3, activation='relu', padding='same')(decoder)\n",
    "# decoder =  UpSampling1D(2)(decoder)\n",
    "decoder = Conv1D(1, 3, activation='sigmoid', padding='same')(decoder)\n",
    "autoencoder = Model(input_img, decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = make_df_parallel(names=X_train, setting='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train.values, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = make_df_parallel(names=X_test, setting='raw')\n",
    "x_test = np.expand_dims(x_test.values, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=1,\n",
    "                batch_size=16,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "#                 callbacks=[TensorBoard(log_dir='../temp_data/logs/fit/', histogram_freq=0, write_graph=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wbtf2",
   "language": "python",
   "name": "wbtf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
