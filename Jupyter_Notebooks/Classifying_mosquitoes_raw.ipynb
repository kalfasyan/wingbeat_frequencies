{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "# import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import utils\n",
    "from wavhandler import *\n",
    "from utils_train import train_test_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: Cichorii.\n",
      "Read 1451 filenames in 0.04 seconds.\n",
      "Loaded data into matrix in 0.50 seconds.\n",
      "Data: LG_drosophila_10_09.\n",
      "Read 5536 filenames in 0.09 seconds.\n",
      "Loaded data into matrix in 1.35 seconds.\n",
      "Data: LG_zapr_26_09.\n",
      "Read 7210 filenames in 0.08 seconds.\n",
      "Loaded data into matrix in 1.82 seconds.\n",
      "Data: D. suzukii.\n",
      "Read 2401 filenames in 0.02 seconds.\n",
      "Loaded data into matrix in 0.65 seconds.\n"
     ]
    }
   ],
   "source": [
    "data1 = Dataset('Leafminers')\n",
    "data1.read(data=data1.target_classes[0], setting='psd_dB', labels='text')\n",
    "data2 = Dataset('LG')\n",
    "data2.read(data=data2.target_classes[0], setting='psd_dB', labels='text')\n",
    "data3 = Dataset('LG')\n",
    "data3.read(data=data3.target_classes[1], setting='psd_dB', labels='text')\n",
    "data4 = Dataset('Pcfruit')\n",
    "data4.read(data=data4.target_classes[1], setting='psd_dB', labels='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753 filenames after cleaning.\n",
      "5277 filenames after cleaning.\n",
      "7002 filenames after cleaning.\n",
      "2373 filenames after cleaning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fnames</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12791</td>\n",
       "      <td>/home/kalfasyan/data/insects/LG/LG_zapr_26_09/...</td>\n",
       "      <td>LG_zapr_26_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7383</td>\n",
       "      <td>/home/kalfasyan/data/insects/LG/LG_zapr_26_09/...</td>\n",
       "      <td>LG_zapr_26_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9661</td>\n",
       "      <td>/home/kalfasyan/data/insects/LG/LG_zapr_26_09/...</td>\n",
       "      <td>LG_zapr_26_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4415</td>\n",
       "      <td>/home/kalfasyan/data/insects/LG/LG_drosophila_...</td>\n",
       "      <td>LG_drosophila_10_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10149</td>\n",
       "      <td>/home/kalfasyan/data/insects/LG/LG_zapr_26_09/...</td>\n",
       "      <td>LG_zapr_26_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4736</td>\n",
       "      <td>/home/kalfasyan/data/insects/LG/LG_drosophila_...</td>\n",
       "      <td>LG_drosophila_10_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1844</td>\n",
       "      <td>/home/kalfasyan/data/insects/LG/LG_drosophila_...</td>\n",
       "      <td>LG_drosophila_10_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7223</td>\n",
       "      <td>/home/kalfasyan/data/insects/LG/LG_zapr_26_09/...</td>\n",
       "      <td>LG_zapr_26_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12033</td>\n",
       "      <td>/home/kalfasyan/data/insects/LG/LG_zapr_26_09/...</td>\n",
       "      <td>LG_zapr_26_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12569</td>\n",
       "      <td>/home/kalfasyan/data/insects/LG/LG_zapr_26_09/...</td>\n",
       "      <td>LG_zapr_26_09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fnames                    y\n",
       "12791  /home/kalfasyan/data/insects/LG/LG_zapr_26_09/...        LG_zapr_26_09\n",
       "7383   /home/kalfasyan/data/insects/LG/LG_zapr_26_09/...        LG_zapr_26_09\n",
       "9661   /home/kalfasyan/data/insects/LG/LG_zapr_26_09/...        LG_zapr_26_09\n",
       "4415   /home/kalfasyan/data/insects/LG/LG_drosophila_...  LG_drosophila_10_09\n",
       "10149  /home/kalfasyan/data/insects/LG/LG_zapr_26_09/...        LG_zapr_26_09\n",
       "4736   /home/kalfasyan/data/insects/LG/LG_drosophila_...  LG_drosophila_10_09\n",
       "1844   /home/kalfasyan/data/insects/LG/LG_drosophila_...  LG_drosophila_10_09\n",
       "7223   /home/kalfasyan/data/insects/LG/LG_zapr_26_09/...        LG_zapr_26_09\n",
       "12033  /home/kalfasyan/data/insects/LG/LG_zapr_26_09/...        LG_zapr_26_09\n",
       "12569  /home/kalfasyan/data/insects/LG/LG_zapr_26_09/...        LG_zapr_26_09"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.clean(plot=False)\n",
    "data2.clean(plot=False)\n",
    "data3.clean(plot=False)\n",
    "data4.clean(plot=False)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['fnames'] = pd.concat([data1.filenames, data2.filenames, data3.filenames, data4.filenames], axis=0).reset_index(drop=True)\n",
    "data['y'] = data.fnames.apply(lambda x: x.split('/')[6])\n",
    "# big.dropna(how='any', axis=1, inplace=True)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data.fnames, data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y = data.filenames.values.reshape(-1,1), data.y.values\n",
    "\n",
    "model_name='first_' \n",
    "setting='raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_weights_path = TEMP_DATADIR + str(model_name) + '.h5'\n",
    "targets = len(np.unique(y))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "if setting == 'psd_dB':\n",
    "    X = transform_data(X, setting=setting)\n",
    "\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = train_test_val_split(X.tolist(),y.tolist(), random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "# Build the Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "inputs = Input(shape=(5000, 1))\n",
    "x = Conv1D(16, 3, activation='relu')(inputs)\n",
    "x = Conv1D(16, 3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv1D(32, 3, activation='relu')(x)\n",
    "x = Conv1D(32, 3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv1D(64, 3, activation='relu')(x)\n",
    "x = Conv1D(64, 3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv1D(256, 3, activation='relu')(x)\n",
    "x = Conv1D(256, 3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.5)(x, training=True)\n",
    "\n",
    "outputs = Dense(targets, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(top_weights_path, monitor = 'val_accuracy', verbose = 1, save_best_only = True, save_weights_only = True),\n",
    "    EarlyStopping(monitor = 'val_accuracy', patience = 6, verbose = 1),\n",
    "    ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.1, patience = 3, verbose = 1),\n",
    "    CSVLogger('model_' + str(model_name) + '.log')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow.keras.backend as K\n",
    "tensorflow.compat.v1.disable_eager_execution()\n",
    "\n",
    "# for some model with dropout ...\n",
    "f = K.function([model.layers[0].input, K.learning_phase()],[model.layers[-1].output])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from utils_train import train_generator, valid_generator\n",
    "target_names = list(np.unique(data.y))\n",
    "batch_size = 32\n",
    "model.fit_generator(train_generator(X_train, y_train, batch_size=batch_size,\n",
    "                                   target_names=target_names,\n",
    "                                   setting=setting),\n",
    "                   steps_per_epoch = int(math.ceil(float(len(X_train)) / float(batch_size))),\n",
    "                   epochs=100,\n",
    "                   validation_data = valid_generator(X_val, y_val,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    target_names=target_names,\n",
    "                                                    setting=setting),\n",
    "                    validation_steps=int(math.ceil(float(len(X_test))/float(batch_size))),\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/kalfasyan/HGST_4TB/Ubudirs/projects/wingbeat_frequencies/Jupyter_Notebooks/temp_data/first_.h5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 5000, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(top_weights_path)\n",
    "\n",
    "your_data = make_df_parallel(names=X_test, setting='raw')\n",
    "your_data = np.float32(your_data.values).reshape((1541,5000,1))\n",
    "\n",
    "your_data = your_data[:400,:,:]\n",
    "your_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 100\n",
    "no_classes = 4\n",
    "x = your_data\n",
    "\n",
    "result = np.zeros((n_iter,) + (x.shape[0], no_classes) )\n",
    "for i in range(n_iter):\n",
    "    result[i, :, :] = f((x,1))[0]\n",
    "    \n",
    "prediction = result.mean(axis=0)\n",
    "uncertainty = result.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006690433972530661"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print( accuracy_score(prediction.argmax(axis=1), np.array(y_test)[:400]) )\n",
    "uncertainty[prediction.argmax(axis=1)].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: Cichorii_v2.\n",
      "Read 3900 filenames in 0.04 seconds.\n",
      "Loaded data into matrix in 0.42 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataa = Dataset('Leafminers')\n",
    "dataa.read(data=data1.target_classes[1], setting='raw', labels='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5000, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_data2 = np.float32(dataa.X.values).reshape((dataa.X.shape[0],5120,1))\n",
    "your_data2 = your_data2[:100, :5000, :]\n",
    "your_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 100\n",
    "no_classes = 4\n",
    "x = your_data2\n",
    "\n",
    "result = np.zeros((n_iter,) + (x.shape[0], no_classes) )\n",
    "for i in range(n_iter):\n",
    "    result[i, :, :] = f((x,1))[0]\n",
    "    \n",
    "prediction = result.mean(axis=0)\n",
    "uncertainty = result.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 3, 2, 1, 2, 1, 3, 2, 3, 2, 3, 2, 1, 2, 1, 1, 1, 2, 3, 3,\n",
       "       2, 1, 3, 3, 1, 2, 3, 3, 3, 2, 2, 2, 2, 1, 1, 3, 3, 0, 1, 2, 1, 1,\n",
       "       0, 2, 1, 2, 1, 1, 3, 2, 3, 3, 1, 0, 3, 3, 2, 1, 0, 2, 3, 2, 2, 3,\n",
       "       3, 1, 3, 3, 2, 3, 1, 1, 3, 2, 3, 1, 2, 2, 3, 3, 1, 3, 1, 3, 1, 3,\n",
       "       0, 3, 3, 1, 3, 1, 3, 3, 1, 1, 3, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# print( accuracy_score(prediction.argmax(axis=1), np.array(your_data2)[:100]) )\n",
    "# uncertainty[prediction.argmax(axis=1)].mean()\n",
    "prediction.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_with_uncertainty(f, x, no_classes, n_iter=100):\n",
    "#     result = np.zeros((n_iter,) + (x.shape[0], no_classes) )\n",
    "\n",
    "#     for i in range(n_iter):\n",
    "#         result[i,:, :] = f((x, 1))[0]\n",
    "\n",
    "#     prediction = result.mean(axis=0)\n",
    "#     uncertainty = result.std(axis=0)\n",
    "#     return prediction, uncertainty    \n",
    "# # predictions, uncertainty = \n",
    "# predict_with_uncertainty(model,your_data, no_classes=4, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(top_weights_path)\n",
    "loss, acc = model.evaluate_generator(valid_generator(X_test, \n",
    "                                                    y_test, \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    setting=setting, \n",
    "                                                    target_names=target_names),\n",
    "        steps = int(math.ceil(float(len(X_test)) / float(batch_size))))\n",
    "\n",
    "print('loss', loss)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "from tensorflow.keras.models import model_from_yaml\n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(TEMP_DATADIR + model_name + \"_raw_final.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
